<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: package sklearn.tree</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong><a href="sklearn.html"><font color="#ffffff">sklearn</font></a>.tree</strong></big></big></font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial"><a href=".">index</a><br><a href="file:c%3A%5Cusers%5Cspidern3mo%5Cappdata%5Clocal%5Cprograms%5Cpython%5Cpython36%5Clib%5Csite-packages%5Csklearn%5Ctree%5C__init__.py">c:\users\spidern3mo\appdata\local\programs\python\python36\lib\site-packages\sklearn\tree\__init__.py</a></font></td></tr></table>
    <p><tt>The&nbsp;:mod:`sklearn.tree`&nbsp;module&nbsp;includes&nbsp;decision&nbsp;tree-based&nbsp;models&nbsp;for<br>
classification&nbsp;and&nbsp;regression.</tt></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Package Contents</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="sklearn.tree._criterion.html">_criterion</a><br>
<a href="sklearn.tree._splitter.html">_splitter</a><br>
</td><td width="25%" valign=top><a href="sklearn.tree._tree.html">_tree</a><br>
<a href="sklearn.tree._utils.html">_utils</a><br>
</td><td width="25%" valign=top><a href="sklearn.tree.export.html">export</a><br>
<a href="sklearn.tree.setup.html">setup</a><br>
</td><td width="25%" valign=top><a href="sklearn.tree.tests.html"><strong>tests</strong>&nbsp;(package)</a><br>
<a href="sklearn.tree.tree.html">tree</a><br>
</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ee77aa">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Classes</strong></big></font></td></tr>
    
<tr><td bgcolor="#ee77aa"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl>
<dt><font face="helvetica, arial"><a href="sklearn.base.html#ClassifierMixin">sklearn.base.ClassifierMixin</a>(<a href="builtins.html#object">builtins.object</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#DecisionTreeClassifier">sklearn.tree.tree.DecisionTreeClassifier</a>(<a href="sklearn.tree.tree.html#BaseDecisionTree">sklearn.tree.tree.BaseDecisionTree</a>, <a href="sklearn.base.html#ClassifierMixin">sklearn.base.ClassifierMixin</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#ExtraTreeClassifier">sklearn.tree.tree.ExtraTreeClassifier</a>
</font></dt></dl>
</dd>
</dl>
</dd>
<dt><font face="helvetica, arial"><a href="sklearn.base.html#RegressorMixin">sklearn.base.RegressorMixin</a>(<a href="builtins.html#object">builtins.object</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#DecisionTreeRegressor">sklearn.tree.tree.DecisionTreeRegressor</a>(<a href="sklearn.tree.tree.html#BaseDecisionTree">sklearn.tree.tree.BaseDecisionTree</a>, <a href="sklearn.base.html#RegressorMixin">sklearn.base.RegressorMixin</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#ExtraTreeRegressor">sklearn.tree.tree.ExtraTreeRegressor</a>
</font></dt></dl>
</dd>
</dl>
</dd>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#BaseDecisionTree">sklearn.tree.tree.BaseDecisionTree</a>(abc.NewBase)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#DecisionTreeClassifier">sklearn.tree.tree.DecisionTreeClassifier</a>(<a href="sklearn.tree.tree.html#BaseDecisionTree">sklearn.tree.tree.BaseDecisionTree</a>, <a href="sklearn.base.html#ClassifierMixin">sklearn.base.ClassifierMixin</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#ExtraTreeClassifier">sklearn.tree.tree.ExtraTreeClassifier</a>
</font></dt></dl>
</dd>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#DecisionTreeRegressor">sklearn.tree.tree.DecisionTreeRegressor</a>(<a href="sklearn.tree.tree.html#BaseDecisionTree">sklearn.tree.tree.BaseDecisionTree</a>, <a href="sklearn.base.html#RegressorMixin">sklearn.base.RegressorMixin</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="sklearn.tree.tree.html#ExtraTreeRegressor">sklearn.tree.tree.ExtraTreeRegressor</a>
</font></dt></dl>
</dd>
</dl>
</dd>
</dl>
 <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="DecisionTreeClassifier">class <strong>DecisionTreeClassifier</strong></a>(<a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>, <a href="sklearn.base.html#ClassifierMixin">sklearn.base.ClassifierMixin</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>A&nbsp;decision&nbsp;tree&nbsp;classifier.<br>
&nbsp;<br>
Read&nbsp;more&nbsp;in&nbsp;the&nbsp;:ref:`User&nbsp;Guide&nbsp;&lt;tree&gt;`.<br>
&nbsp;<br>
Parameters<br>
----------<br>
criterion&nbsp;:&nbsp;string,&nbsp;optional&nbsp;(default="gini")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;function&nbsp;to&nbsp;measure&nbsp;the&nbsp;quality&nbsp;of&nbsp;a&nbsp;split.&nbsp;Supported&nbsp;criteria&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;"gini"&nbsp;for&nbsp;the&nbsp;Gini&nbsp;impurity&nbsp;and&nbsp;"entropy"&nbsp;for&nbsp;the&nbsp;information&nbsp;gain.<br>
&nbsp;<br>
splitter&nbsp;:&nbsp;string,&nbsp;optional&nbsp;(default="best")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;strategy&nbsp;used&nbsp;to&nbsp;choose&nbsp;the&nbsp;split&nbsp;at&nbsp;each&nbsp;node.&nbsp;Supported<br>
&nbsp;&nbsp;&nbsp;&nbsp;strategies&nbsp;are&nbsp;"best"&nbsp;to&nbsp;choose&nbsp;the&nbsp;best&nbsp;split&nbsp;and&nbsp;"random"&nbsp;to&nbsp;choose<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;best&nbsp;random&nbsp;split.<br>
&nbsp;<br>
max_depth&nbsp;:&nbsp;int&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree.&nbsp;If&nbsp;None,&nbsp;then&nbsp;nodes&nbsp;are&nbsp;expanded&nbsp;until<br>
&nbsp;&nbsp;&nbsp;&nbsp;all&nbsp;leaves&nbsp;are&nbsp;pure&nbsp;or&nbsp;until&nbsp;all&nbsp;leaves&nbsp;contain&nbsp;less&nbsp;than<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;samples.<br>
&nbsp;<br>
min_samples_split&nbsp;:&nbsp;int,&nbsp;float,&nbsp;optional&nbsp;(default=2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`min_samples_split`&nbsp;as&nbsp;the&nbsp;minimum&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`min_samples_split`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ceil(min_samples_split&nbsp;*&nbsp;n_samples)`&nbsp;are&nbsp;the&nbsp;minimum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;split.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Added&nbsp;float&nbsp;values&nbsp;for&nbsp;fractions.<br>
&nbsp;<br>
min_samples_leaf&nbsp;:&nbsp;int,&nbsp;float,&nbsp;optional&nbsp;(default=1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;be&nbsp;at&nbsp;a&nbsp;leaf&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;split&nbsp;point&nbsp;at&nbsp;any&nbsp;depth&nbsp;will&nbsp;only&nbsp;be&nbsp;considered&nbsp;if&nbsp;it&nbsp;leaves&nbsp;at<br>
&nbsp;&nbsp;&nbsp;&nbsp;least&nbsp;``min_samples_leaf``&nbsp;training&nbsp;samples&nbsp;in&nbsp;each&nbsp;of&nbsp;the&nbsp;left&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;right&nbsp;branches.&nbsp;&nbsp;This&nbsp;may&nbsp;have&nbsp;the&nbsp;effect&nbsp;of&nbsp;smoothing&nbsp;the&nbsp;model,<br>
&nbsp;&nbsp;&nbsp;&nbsp;especially&nbsp;in&nbsp;regression.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`min_samples_leaf`&nbsp;as&nbsp;the&nbsp;minimum&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`min_samples_leaf`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ceil(min_samples_leaf&nbsp;*&nbsp;n_samples)`&nbsp;are&nbsp;the&nbsp;minimum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;node.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Added&nbsp;float&nbsp;values&nbsp;for&nbsp;fractions.<br>
&nbsp;<br>
min_weight_fraction_leaf&nbsp;:&nbsp;float,&nbsp;optional&nbsp;(default=0.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;weighted&nbsp;fraction&nbsp;of&nbsp;the&nbsp;sum&nbsp;total&nbsp;of&nbsp;weights&nbsp;(of&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;input&nbsp;samples)&nbsp;required&nbsp;to&nbsp;be&nbsp;at&nbsp;a&nbsp;leaf&nbsp;node.&nbsp;Samples&nbsp;have<br>
&nbsp;&nbsp;&nbsp;&nbsp;equal&nbsp;weight&nbsp;when&nbsp;sample_weight&nbsp;is&nbsp;not&nbsp;provided.<br>
&nbsp;<br>
max_features&nbsp;:&nbsp;int,&nbsp;float,&nbsp;string&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;to&nbsp;consider&nbsp;when&nbsp;looking&nbsp;for&nbsp;the&nbsp;best&nbsp;split:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`max_features`&nbsp;features&nbsp;at&nbsp;each&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`max_features`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`int(max_features&nbsp;*&nbsp;n_features)`&nbsp;features&nbsp;are&nbsp;considered&nbsp;at&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"auto",&nbsp;then&nbsp;`max_features=sqrt(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"sqrt",&nbsp;then&nbsp;`max_features=sqrt(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"log2",&nbsp;then&nbsp;`max_features=log2(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;None,&nbsp;then&nbsp;`max_features=n_features`.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Note:&nbsp;the&nbsp;search&nbsp;for&nbsp;a&nbsp;split&nbsp;does&nbsp;not&nbsp;stop&nbsp;until&nbsp;at&nbsp;least&nbsp;one<br>
&nbsp;&nbsp;&nbsp;&nbsp;valid&nbsp;partition&nbsp;of&nbsp;the&nbsp;node&nbsp;samples&nbsp;is&nbsp;found,&nbsp;even&nbsp;if&nbsp;it&nbsp;requires&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;effectively&nbsp;inspect&nbsp;more&nbsp;than&nbsp;``max_features``&nbsp;features.<br>
&nbsp;<br>
random_state&nbsp;:&nbsp;int,&nbsp;RandomState&nbsp;instance&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;int,&nbsp;random_state&nbsp;is&nbsp;the&nbsp;seed&nbsp;used&nbsp;by&nbsp;the&nbsp;random&nbsp;number&nbsp;generator;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;RandomState&nbsp;instance,&nbsp;random_state&nbsp;is&nbsp;the&nbsp;random&nbsp;number&nbsp;generator;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None,&nbsp;the&nbsp;random&nbsp;number&nbsp;generator&nbsp;is&nbsp;the&nbsp;RandomState&nbsp;instance&nbsp;used<br>
&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;`np.random`.<br>
&nbsp;<br>
max_leaf_nodes&nbsp;:&nbsp;int&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Grow&nbsp;a&nbsp;tree&nbsp;with&nbsp;``max_leaf_nodes``&nbsp;in&nbsp;best-first&nbsp;fashion.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Best&nbsp;nodes&nbsp;are&nbsp;defined&nbsp;as&nbsp;relative&nbsp;reduction&nbsp;in&nbsp;impurity.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None&nbsp;then&nbsp;unlimited&nbsp;number&nbsp;of&nbsp;leaf&nbsp;nodes.<br>
&nbsp;<br>
min_impurity_decrease&nbsp;:&nbsp;float,&nbsp;optional&nbsp;(default=0.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;node&nbsp;will&nbsp;be&nbsp;split&nbsp;if&nbsp;this&nbsp;split&nbsp;induces&nbsp;a&nbsp;decrease&nbsp;of&nbsp;the&nbsp;impurity<br>
&nbsp;&nbsp;&nbsp;&nbsp;greater&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;this&nbsp;value.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;weighted&nbsp;impurity&nbsp;decrease&nbsp;equation&nbsp;is&nbsp;the&nbsp;following::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;N_t&nbsp;/&nbsp;N&nbsp;*&nbsp;(impurity&nbsp;-&nbsp;N_t_R&nbsp;/&nbsp;N_t&nbsp;*&nbsp;right_impurity<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;N_t_L&nbsp;/&nbsp;N_t&nbsp;*&nbsp;left_impurity)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;where&nbsp;``N``&nbsp;is&nbsp;the&nbsp;total&nbsp;number&nbsp;of&nbsp;samples,&nbsp;``N_t``&nbsp;is&nbsp;the&nbsp;number&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;samples&nbsp;at&nbsp;the&nbsp;current&nbsp;node,&nbsp;``N_t_L``&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;left&nbsp;child,&nbsp;and&nbsp;``N_t_R``&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;right&nbsp;child.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;``N``,&nbsp;``N_t``,&nbsp;``N_t_R``&nbsp;and&nbsp;``N_t_L``&nbsp;all&nbsp;refer&nbsp;to&nbsp;the&nbsp;weighted&nbsp;sum,<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;``sample_weight``&nbsp;is&nbsp;passed.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionadded::&nbsp;0.19<br>
&nbsp;<br>
min_impurity_split&nbsp;:&nbsp;float,&nbsp;(default=1e-7)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Threshold&nbsp;for&nbsp;early&nbsp;stopping&nbsp;in&nbsp;tree&nbsp;growth.&nbsp;A&nbsp;node&nbsp;will&nbsp;split<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;its&nbsp;impurity&nbsp;is&nbsp;above&nbsp;the&nbsp;threshold,&nbsp;otherwise&nbsp;it&nbsp;is&nbsp;a&nbsp;leaf.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;deprecated::&nbsp;0.19<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_split``&nbsp;has&nbsp;been&nbsp;deprecated&nbsp;in&nbsp;favor&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_decrease``&nbsp;in&nbsp;0.19.&nbsp;The&nbsp;default&nbsp;value&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_split``&nbsp;will&nbsp;change&nbsp;from&nbsp;1e-7&nbsp;to&nbsp;0&nbsp;in&nbsp;0.23&nbsp;and&nbsp;it<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;be&nbsp;removed&nbsp;in&nbsp;0.25.&nbsp;Use&nbsp;``min_impurity_decrease``&nbsp;instead.<br>
&nbsp;<br>
class_weight&nbsp;:&nbsp;dict,&nbsp;list&nbsp;of&nbsp;dicts,&nbsp;"balanced"&nbsp;or&nbsp;None,&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Weights&nbsp;associated&nbsp;with&nbsp;classes&nbsp;in&nbsp;the&nbsp;form&nbsp;``{class_label:&nbsp;weight}``.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;not&nbsp;given,&nbsp;all&nbsp;classes&nbsp;are&nbsp;supposed&nbsp;to&nbsp;have&nbsp;weight&nbsp;one.&nbsp;For<br>
&nbsp;&nbsp;&nbsp;&nbsp;multi-output&nbsp;problems,&nbsp;a&nbsp;list&nbsp;of&nbsp;dicts&nbsp;can&nbsp;be&nbsp;provided&nbsp;in&nbsp;the&nbsp;same<br>
&nbsp;&nbsp;&nbsp;&nbsp;order&nbsp;as&nbsp;the&nbsp;columns&nbsp;of&nbsp;y.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Note&nbsp;that&nbsp;for&nbsp;multioutput&nbsp;(including&nbsp;multilabel)&nbsp;weights&nbsp;should&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;defined&nbsp;for&nbsp;each&nbsp;class&nbsp;of&nbsp;every&nbsp;column&nbsp;in&nbsp;its&nbsp;own&nbsp;dict.&nbsp;For&nbsp;example,<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;four-class&nbsp;multilabel&nbsp;classification&nbsp;weights&nbsp;should&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;[{0:&nbsp;1,&nbsp;1:&nbsp;1},&nbsp;{0:&nbsp;1,&nbsp;1:&nbsp;5},&nbsp;{0:&nbsp;1,&nbsp;1:&nbsp;1},&nbsp;{0:&nbsp;1,&nbsp;1:&nbsp;1}]&nbsp;instead&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;[{1:1},&nbsp;{2:5},&nbsp;{3:1},&nbsp;{4:1}].<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;"balanced"&nbsp;mode&nbsp;uses&nbsp;the&nbsp;values&nbsp;of&nbsp;y&nbsp;to&nbsp;automatically&nbsp;adjust<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;inversely&nbsp;proportional&nbsp;to&nbsp;class&nbsp;frequencies&nbsp;in&nbsp;the&nbsp;input&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;as&nbsp;``n_samples&nbsp;/&nbsp;(n_classes&nbsp;*&nbsp;np.bincount(y))``<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;multi-output,&nbsp;the&nbsp;weights&nbsp;of&nbsp;each&nbsp;column&nbsp;of&nbsp;y&nbsp;will&nbsp;be&nbsp;multiplied.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Note&nbsp;that&nbsp;these&nbsp;weights&nbsp;will&nbsp;be&nbsp;multiplied&nbsp;with&nbsp;sample_weight&nbsp;(passed<br>
&nbsp;&nbsp;&nbsp;&nbsp;through&nbsp;the&nbsp;fit&nbsp;method)&nbsp;if&nbsp;sample_weight&nbsp;is&nbsp;specified.<br>
&nbsp;<br>
presort&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;presort&nbsp;the&nbsp;data&nbsp;to&nbsp;speed&nbsp;up&nbsp;the&nbsp;finding&nbsp;of&nbsp;best&nbsp;splits&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;fitting.&nbsp;For&nbsp;the&nbsp;default&nbsp;settings&nbsp;of&nbsp;a&nbsp;decision&nbsp;tree&nbsp;on&nbsp;large<br>
&nbsp;&nbsp;&nbsp;&nbsp;datasets,&nbsp;setting&nbsp;this&nbsp;to&nbsp;true&nbsp;may&nbsp;slow&nbsp;down&nbsp;the&nbsp;training&nbsp;process.<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;using&nbsp;either&nbsp;a&nbsp;smaller&nbsp;dataset&nbsp;or&nbsp;a&nbsp;restricted&nbsp;depth,&nbsp;this&nbsp;may<br>
&nbsp;&nbsp;&nbsp;&nbsp;speed&nbsp;up&nbsp;the&nbsp;training.<br>
&nbsp;<br>
Attributes<br>
----------<br>
classes_&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_classes]&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;such&nbsp;arrays<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;classes&nbsp;labels&nbsp;(single&nbsp;output&nbsp;problem),<br>
&nbsp;&nbsp;&nbsp;&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;arrays&nbsp;of&nbsp;class&nbsp;labels&nbsp;(multi-output&nbsp;problem).<br>
&nbsp;<br>
feature_importances_&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;feature&nbsp;importances.&nbsp;The&nbsp;higher,&nbsp;the&nbsp;more&nbsp;important&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;feature.&nbsp;The&nbsp;importance&nbsp;of&nbsp;a&nbsp;feature&nbsp;is&nbsp;computed&nbsp;as&nbsp;the&nbsp;(normalized)<br>
&nbsp;&nbsp;&nbsp;&nbsp;total&nbsp;reduction&nbsp;of&nbsp;the&nbsp;criterion&nbsp;brought&nbsp;by&nbsp;that&nbsp;feature.&nbsp;&nbsp;It&nbsp;is&nbsp;also<br>
&nbsp;&nbsp;&nbsp;&nbsp;known&nbsp;as&nbsp;the&nbsp;Gini&nbsp;importance&nbsp;[4]_.<br>
&nbsp;<br>
max_features_&nbsp;:&nbsp;int,<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;inferred&nbsp;value&nbsp;of&nbsp;max_features.<br>
&nbsp;<br>
n_classes_&nbsp;:&nbsp;int&nbsp;or&nbsp;list<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;classes&nbsp;(for&nbsp;single&nbsp;output&nbsp;problems),<br>
&nbsp;&nbsp;&nbsp;&nbsp;or&nbsp;a&nbsp;list&nbsp;containing&nbsp;the&nbsp;number&nbsp;of&nbsp;classes&nbsp;for&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;output&nbsp;(for&nbsp;multi-output&nbsp;problems).<br>
&nbsp;<br>
n_features_&nbsp;:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;when&nbsp;``fit``&nbsp;is&nbsp;performed.<br>
&nbsp;<br>
n_outputs_&nbsp;:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;outputs&nbsp;when&nbsp;``fit``&nbsp;is&nbsp;performed.<br>
&nbsp;<br>
tree_&nbsp;:&nbsp;Tree&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;underlying&nbsp;Tree&nbsp;object.&nbsp;Please&nbsp;refer&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``help(sklearn.tree._tree.Tree)``&nbsp;for&nbsp;attributes&nbsp;of&nbsp;Tree&nbsp;object&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;basic&nbsp;usage&nbsp;of&nbsp;these&nbsp;attributes.<br>
&nbsp;<br>
Notes<br>
-----<br>
The&nbsp;default&nbsp;values&nbsp;for&nbsp;the&nbsp;parameters&nbsp;controlling&nbsp;the&nbsp;size&nbsp;of&nbsp;the&nbsp;trees<br>
(e.g.&nbsp;``max_depth``,&nbsp;``min_samples_leaf``,&nbsp;etc.)&nbsp;lead&nbsp;to&nbsp;fully&nbsp;grown&nbsp;and<br>
unpruned&nbsp;trees&nbsp;which&nbsp;can&nbsp;potentially&nbsp;be&nbsp;very&nbsp;large&nbsp;on&nbsp;some&nbsp;data&nbsp;sets.&nbsp;To<br>
reduce&nbsp;memory&nbsp;consumption,&nbsp;the&nbsp;complexity&nbsp;and&nbsp;size&nbsp;of&nbsp;the&nbsp;trees&nbsp;should&nbsp;be<br>
controlled&nbsp;by&nbsp;setting&nbsp;those&nbsp;parameter&nbsp;values.<br>
&nbsp;<br>
The&nbsp;features&nbsp;are&nbsp;always&nbsp;randomly&nbsp;permuted&nbsp;at&nbsp;each&nbsp;split.&nbsp;Therefore,<br>
the&nbsp;best&nbsp;found&nbsp;split&nbsp;may&nbsp;vary,&nbsp;even&nbsp;with&nbsp;the&nbsp;same&nbsp;training&nbsp;data&nbsp;and<br>
``max_features=n_features``,&nbsp;if&nbsp;the&nbsp;improvement&nbsp;of&nbsp;the&nbsp;criterion&nbsp;is<br>
identical&nbsp;for&nbsp;several&nbsp;splits&nbsp;enumerated&nbsp;during&nbsp;the&nbsp;search&nbsp;of&nbsp;the&nbsp;best<br>
split.&nbsp;To&nbsp;obtain&nbsp;a&nbsp;deterministic&nbsp;behaviour&nbsp;during&nbsp;fitting,<br>
``random_state``&nbsp;has&nbsp;to&nbsp;be&nbsp;fixed.<br>
&nbsp;<br>
See&nbsp;also<br>
--------<br>
<a href="#DecisionTreeRegressor">DecisionTreeRegressor</a><br>
&nbsp;<br>
References<br>
----------<br>
&nbsp;<br>
..&nbsp;[1]&nbsp;https://en.wikipedia.org/wiki/Decision_tree_learning<br>
&nbsp;<br>
..&nbsp;[2]&nbsp;L.&nbsp;Breiman,&nbsp;J.&nbsp;Friedman,&nbsp;R.&nbsp;Olshen,&nbsp;and&nbsp;C.&nbsp;Stone,&nbsp;"Classification<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;Regression&nbsp;Trees",&nbsp;Wadsworth,&nbsp;Belmont,&nbsp;CA,&nbsp;1984.<br>
&nbsp;<br>
..&nbsp;[3]&nbsp;T.&nbsp;Hastie,&nbsp;R.&nbsp;Tibshirani&nbsp;and&nbsp;J.&nbsp;Friedman.&nbsp;"Elements&nbsp;of&nbsp;Statistical<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Learning",&nbsp;Springer,&nbsp;2009.<br>
&nbsp;<br>
..&nbsp;[4]&nbsp;L.&nbsp;Breiman,&nbsp;and&nbsp;A.&nbsp;Cutler,&nbsp;"Random&nbsp;Forests",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm<br>
&nbsp;<br>
Examples<br>
--------<br>
&gt;&gt;&gt;&nbsp;from&nbsp;sklearn.datasets&nbsp;import&nbsp;load_iris<br>
&gt;&gt;&gt;&nbsp;from&nbsp;sklearn.model_selection&nbsp;import&nbsp;cross_val_score<br>
&gt;&gt;&gt;&nbsp;from&nbsp;sklearn.tree&nbsp;import&nbsp;<a href="#DecisionTreeClassifier">DecisionTreeClassifier</a><br>
&gt;&gt;&gt;&nbsp;clf&nbsp;=&nbsp;<a href="#DecisionTreeClassifier">DecisionTreeClassifier</a>(random_state=0)<br>
&gt;&gt;&gt;&nbsp;iris&nbsp;=&nbsp;load_iris()<br>
&gt;&gt;&gt;&nbsp;cross_val_score(clf,&nbsp;iris.data,&nbsp;iris.target,&nbsp;cv=10)<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;doctest:&nbsp;+SKIP<br>
...<br>
array([&nbsp;1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,&nbsp;&nbsp;0.93...,&nbsp;&nbsp;0.86...,&nbsp;&nbsp;0.93...,&nbsp;&nbsp;0.93...,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.93...,&nbsp;&nbsp;0.93...,&nbsp;&nbsp;1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,&nbsp;&nbsp;0.93...,&nbsp;&nbsp;1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;])<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="sklearn.tree.tree.html#DecisionTreeClassifier">DecisionTreeClassifier</a></dd>
<dd><a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a></dd>
<dd>abc.NewBase</dd>
<dd><a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a></dd>
<dd><a href="sklearn.base.html#ClassifierMixin">sklearn.base.ClassifierMixin</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="DecisionTreeClassifier-__init__"><strong>__init__</strong></a>(self, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="DecisionTreeClassifier-fit"><strong>fit</strong></a>(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)</dt><dd><tt>Build&nbsp;a&nbsp;decision&nbsp;tree&nbsp;classifier&nbsp;from&nbsp;the&nbsp;training&nbsp;set&nbsp;(X,&nbsp;y).<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;training&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csc_matrix``.<br>
&nbsp;<br>
y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;[n_samples,&nbsp;n_outputs]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;target&nbsp;values&nbsp;(class&nbsp;labels)&nbsp;as&nbsp;integers&nbsp;or&nbsp;strings.<br>
&nbsp;<br>
sample_weight&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sample&nbsp;weights.&nbsp;If&nbsp;None,&nbsp;then&nbsp;samples&nbsp;are&nbsp;equally&nbsp;weighted.&nbsp;Splits<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;would&nbsp;create&nbsp;child&nbsp;nodes&nbsp;with&nbsp;net&nbsp;zero&nbsp;or&nbsp;negative&nbsp;weight&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;ignored&nbsp;while&nbsp;searching&nbsp;for&nbsp;a&nbsp;split&nbsp;in&nbsp;each&nbsp;node.&nbsp;Splits&nbsp;are&nbsp;also<br>
&nbsp;&nbsp;&nbsp;&nbsp;ignored&nbsp;if&nbsp;they&nbsp;would&nbsp;result&nbsp;in&nbsp;any&nbsp;single&nbsp;class&nbsp;carrying&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;negative&nbsp;weight&nbsp;in&nbsp;either&nbsp;child&nbsp;node.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
X_idx_sorted&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features],&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;indexes&nbsp;of&nbsp;the&nbsp;sorted&nbsp;training&nbsp;input&nbsp;samples.&nbsp;If&nbsp;many&nbsp;tree<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;grown&nbsp;on&nbsp;the&nbsp;same&nbsp;dataset,&nbsp;this&nbsp;allows&nbsp;the&nbsp;ordering&nbsp;to&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;between&nbsp;trees.&nbsp;If&nbsp;None,&nbsp;the&nbsp;data&nbsp;will&nbsp;be&nbsp;sorted&nbsp;here.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;to&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
self&nbsp;:&nbsp;object</tt></dd></dl>

<dl><dt><a name="DecisionTreeClassifier-predict_log_proba"><strong>predict_log_proba</strong></a>(self, X)</dt><dd><tt>Predict&nbsp;class&nbsp;log-probabilities&nbsp;of&nbsp;the&nbsp;input&nbsp;samples&nbsp;X.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
Returns<br>
-------<br>
p&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_classes],&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;n_outputs<br>
&nbsp;&nbsp;&nbsp;&nbsp;such&nbsp;arrays&nbsp;if&nbsp;n_outputs&nbsp;&gt;&nbsp;1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;class&nbsp;log-probabilities&nbsp;of&nbsp;the&nbsp;input&nbsp;samples.&nbsp;The&nbsp;order&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes&nbsp;corresponds&nbsp;to&nbsp;that&nbsp;in&nbsp;the&nbsp;attribute&nbsp;`classes_`.</tt></dd></dl>

<dl><dt><a name="DecisionTreeClassifier-predict_proba"><strong>predict_proba</strong></a>(self, X, check_input=True)</dt><dd><tt>Predict&nbsp;class&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;input&nbsp;samples&nbsp;X.<br>
&nbsp;<br>
The&nbsp;predicted&nbsp;class&nbsp;probability&nbsp;is&nbsp;the&nbsp;fraction&nbsp;of&nbsp;samples&nbsp;of&nbsp;the&nbsp;same<br>
class&nbsp;in&nbsp;a&nbsp;leaf.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;bool<br>
&nbsp;&nbsp;&nbsp;&nbsp;Run&nbsp;check_array&nbsp;on&nbsp;X.<br>
&nbsp;<br>
Returns<br>
-------<br>
p&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_classes],&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;n_outputs<br>
&nbsp;&nbsp;&nbsp;&nbsp;such&nbsp;arrays&nbsp;if&nbsp;n_outputs&nbsp;&gt;&nbsp;1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;class&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;input&nbsp;samples.&nbsp;The&nbsp;order&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes&nbsp;corresponds&nbsp;to&nbsp;that&nbsp;in&nbsp;the&nbsp;attribute&nbsp;`classes_`.</tt></dd></dl>

<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>__abstractmethods__</strong> = frozenset()</dl>

<hr>
Methods inherited from <a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>:<br>
<dl><dt><a name="DecisionTreeClassifier-apply"><strong>apply</strong></a>(self, X, check_input=True)</dt><dd><tt>Returns&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;leaf&nbsp;that&nbsp;each&nbsp;sample&nbsp;is&nbsp;predicted&nbsp;as.<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.17<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array_like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
X_leaves&nbsp;:&nbsp;array_like,&nbsp;shape&nbsp;=&nbsp;[n_samples,]<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;each&nbsp;datapoint&nbsp;x&nbsp;in&nbsp;X,&nbsp;return&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;leaf&nbsp;x<br>
&nbsp;&nbsp;&nbsp;&nbsp;ends&nbsp;up&nbsp;in.&nbsp;Leaves&nbsp;are&nbsp;numbered&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;``[0;&nbsp;self.<strong>tree_</strong>.node_count)``,&nbsp;possibly&nbsp;with&nbsp;gaps&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;numbering.</tt></dd></dl>

<dl><dt><a name="DecisionTreeClassifier-decision_path"><strong>decision_path</strong></a>(self, X, check_input=True)</dt><dd><tt>Return&nbsp;the&nbsp;decision&nbsp;path&nbsp;in&nbsp;the&nbsp;tree<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.18<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array_like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
indicator&nbsp;:&nbsp;sparse&nbsp;csr&nbsp;array,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_nodes]<br>
&nbsp;&nbsp;&nbsp;&nbsp;Return&nbsp;a&nbsp;node&nbsp;indicator&nbsp;matrix&nbsp;where&nbsp;non&nbsp;zero&nbsp;elements<br>
&nbsp;&nbsp;&nbsp;&nbsp;indicates&nbsp;that&nbsp;the&nbsp;samples&nbsp;goes&nbsp;through&nbsp;the&nbsp;nodes.</tt></dd></dl>

<dl><dt><a name="DecisionTreeClassifier-predict"><strong>predict</strong></a>(self, X, check_input=True)</dt><dd><tt>Predict&nbsp;class&nbsp;or&nbsp;regression&nbsp;value&nbsp;for&nbsp;X.<br>
&nbsp;<br>
For&nbsp;a&nbsp;classification&nbsp;model,&nbsp;the&nbsp;predicted&nbsp;class&nbsp;for&nbsp;each&nbsp;sample&nbsp;in&nbsp;X&nbsp;is<br>
returned.&nbsp;For&nbsp;a&nbsp;regression&nbsp;model,&nbsp;the&nbsp;predicted&nbsp;value&nbsp;based&nbsp;on&nbsp;X&nbsp;is<br>
returned.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
y&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;[n_samples,&nbsp;n_outputs]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;predicted&nbsp;classes,&nbsp;or&nbsp;the&nbsp;predict&nbsp;values.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>:<br>
<dl><dt><strong>feature_importances_</strong></dt>
<dd><tt>Return&nbsp;the&nbsp;feature&nbsp;importances.<br>
&nbsp;<br>
The&nbsp;importance&nbsp;of&nbsp;a&nbsp;feature&nbsp;is&nbsp;computed&nbsp;as&nbsp;the&nbsp;(normalized)&nbsp;total<br>
reduction&nbsp;of&nbsp;the&nbsp;criterion&nbsp;brought&nbsp;by&nbsp;that&nbsp;feature.<br>
It&nbsp;is&nbsp;also&nbsp;known&nbsp;as&nbsp;the&nbsp;Gini&nbsp;importance.<br>
&nbsp;<br>
Returns<br>
-------<br>
feature_importances_&nbsp;:&nbsp;array,&nbsp;shape&nbsp;=&nbsp;[n_features]</tt></dd>
</dl>
<hr>
Methods inherited from <a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a>:<br>
<dl><dt><a name="DecisionTreeClassifier-__getstate__"><strong>__getstate__</strong></a>(self)</dt></dl>

<dl><dt><a name="DecisionTreeClassifier-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="DecisionTreeClassifier-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="DecisionTreeClassifier-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><tt>Get&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
Parameters<br>
----------<br>
deep&nbsp;:&nbsp;boolean,&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;True,&nbsp;will&nbsp;return&nbsp;the&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;contained&nbsp;subobjects&nbsp;that&nbsp;are&nbsp;estimators.<br>
&nbsp;<br>
Returns<br>
-------<br>
params&nbsp;:&nbsp;mapping&nbsp;of&nbsp;string&nbsp;to&nbsp;any<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;names&nbsp;mapped&nbsp;to&nbsp;their&nbsp;values.</tt></dd></dl>

<dl><dt><a name="DecisionTreeClassifier-set_params"><strong>set_params</strong></a>(self, **params)</dt><dd><tt>Set&nbsp;the&nbsp;parameters&nbsp;of&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
The&nbsp;method&nbsp;works&nbsp;on&nbsp;simple&nbsp;estimators&nbsp;as&nbsp;well&nbsp;as&nbsp;on&nbsp;nested&nbsp;objects<br>
(such&nbsp;as&nbsp;pipelines).&nbsp;The&nbsp;latter&nbsp;have&nbsp;parameters&nbsp;of&nbsp;the&nbsp;form<br>
``&lt;component&gt;__&lt;parameter&gt;``&nbsp;so&nbsp;that&nbsp;it's&nbsp;possible&nbsp;to&nbsp;update&nbsp;each<br>
component&nbsp;of&nbsp;a&nbsp;nested&nbsp;object.<br>
&nbsp;<br>
Returns<br>
-------<br>
self</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Methods inherited from <a href="sklearn.base.html#ClassifierMixin">sklearn.base.ClassifierMixin</a>:<br>
<dl><dt><a name="DecisionTreeClassifier-score"><strong>score</strong></a>(self, X, y, sample_weight=None)</dt><dd><tt>Returns&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;on&nbsp;the&nbsp;given&nbsp;test&nbsp;data&nbsp;and&nbsp;labels.<br>
&nbsp;<br>
In&nbsp;multi-label&nbsp;classification,&nbsp;this&nbsp;is&nbsp;the&nbsp;subset&nbsp;accuracy<br>
which&nbsp;is&nbsp;a&nbsp;harsh&nbsp;metric&nbsp;since&nbsp;you&nbsp;require&nbsp;for&nbsp;each&nbsp;sample&nbsp;that<br>
each&nbsp;label&nbsp;set&nbsp;be&nbsp;correctly&nbsp;predicted.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;(n_samples,&nbsp;n_features)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Test&nbsp;samples.<br>
&nbsp;<br>
y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;(n_samples)&nbsp;or&nbsp;(n_samples,&nbsp;n_outputs)<br>
&nbsp;&nbsp;&nbsp;&nbsp;True&nbsp;labels&nbsp;for&nbsp;X.<br>
&nbsp;<br>
sample_weight&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples],&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sample&nbsp;weights.<br>
&nbsp;<br>
Returns<br>
-------<br>
score&nbsp;:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;Mean&nbsp;accuracy&nbsp;of&nbsp;self.<a href="#DecisionTreeClassifier-predict">predict</a>(X)&nbsp;wrt.&nbsp;y.</tt></dd></dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="DecisionTreeRegressor">class <strong>DecisionTreeRegressor</strong></a>(<a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>, <a href="sklearn.base.html#RegressorMixin">sklearn.base.RegressorMixin</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>A&nbsp;decision&nbsp;tree&nbsp;regressor.<br>
&nbsp;<br>
Read&nbsp;more&nbsp;in&nbsp;the&nbsp;:ref:`User&nbsp;Guide&nbsp;&lt;tree&gt;`.<br>
&nbsp;<br>
Parameters<br>
----------<br>
criterion&nbsp;:&nbsp;string,&nbsp;optional&nbsp;(default="mse")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;function&nbsp;to&nbsp;measure&nbsp;the&nbsp;quality&nbsp;of&nbsp;a&nbsp;split.&nbsp;Supported&nbsp;criteria<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;"mse"&nbsp;for&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error,&nbsp;which&nbsp;is&nbsp;equal&nbsp;to&nbsp;variance<br>
&nbsp;&nbsp;&nbsp;&nbsp;reduction&nbsp;as&nbsp;feature&nbsp;selection&nbsp;criterion&nbsp;and&nbsp;minimizes&nbsp;the&nbsp;L2&nbsp;loss<br>
&nbsp;&nbsp;&nbsp;&nbsp;using&nbsp;the&nbsp;mean&nbsp;of&nbsp;each&nbsp;terminal&nbsp;node,&nbsp;"friedman_mse",&nbsp;which&nbsp;uses&nbsp;mean<br>
&nbsp;&nbsp;&nbsp;&nbsp;squared&nbsp;error&nbsp;with&nbsp;Friedman's&nbsp;improvement&nbsp;score&nbsp;for&nbsp;potential&nbsp;splits,<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;"mae"&nbsp;for&nbsp;the&nbsp;mean&nbsp;absolute&nbsp;error,&nbsp;which&nbsp;minimizes&nbsp;the&nbsp;L1&nbsp;loss<br>
&nbsp;&nbsp;&nbsp;&nbsp;using&nbsp;the&nbsp;median&nbsp;of&nbsp;each&nbsp;terminal&nbsp;node.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionadded::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mean&nbsp;Absolute&nbsp;Error&nbsp;(MAE)&nbsp;criterion.<br>
&nbsp;<br>
splitter&nbsp;:&nbsp;string,&nbsp;optional&nbsp;(default="best")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;strategy&nbsp;used&nbsp;to&nbsp;choose&nbsp;the&nbsp;split&nbsp;at&nbsp;each&nbsp;node.&nbsp;Supported<br>
&nbsp;&nbsp;&nbsp;&nbsp;strategies&nbsp;are&nbsp;"best"&nbsp;to&nbsp;choose&nbsp;the&nbsp;best&nbsp;split&nbsp;and&nbsp;"random"&nbsp;to&nbsp;choose<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;best&nbsp;random&nbsp;split.<br>
&nbsp;<br>
max_depth&nbsp;:&nbsp;int&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree.&nbsp;If&nbsp;None,&nbsp;then&nbsp;nodes&nbsp;are&nbsp;expanded&nbsp;until<br>
&nbsp;&nbsp;&nbsp;&nbsp;all&nbsp;leaves&nbsp;are&nbsp;pure&nbsp;or&nbsp;until&nbsp;all&nbsp;leaves&nbsp;contain&nbsp;less&nbsp;than<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;samples.<br>
&nbsp;<br>
min_samples_split&nbsp;:&nbsp;int,&nbsp;float,&nbsp;optional&nbsp;(default=2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`min_samples_split`&nbsp;as&nbsp;the&nbsp;minimum&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`min_samples_split`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ceil(min_samples_split&nbsp;*&nbsp;n_samples)`&nbsp;are&nbsp;the&nbsp;minimum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;split.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Added&nbsp;float&nbsp;values&nbsp;for&nbsp;fractions.<br>
&nbsp;<br>
min_samples_leaf&nbsp;:&nbsp;int,&nbsp;float,&nbsp;optional&nbsp;(default=1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;be&nbsp;at&nbsp;a&nbsp;leaf&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;split&nbsp;point&nbsp;at&nbsp;any&nbsp;depth&nbsp;will&nbsp;only&nbsp;be&nbsp;considered&nbsp;if&nbsp;it&nbsp;leaves&nbsp;at<br>
&nbsp;&nbsp;&nbsp;&nbsp;least&nbsp;``min_samples_leaf``&nbsp;training&nbsp;samples&nbsp;in&nbsp;each&nbsp;of&nbsp;the&nbsp;left&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;right&nbsp;branches.&nbsp;&nbsp;This&nbsp;may&nbsp;have&nbsp;the&nbsp;effect&nbsp;of&nbsp;smoothing&nbsp;the&nbsp;model,<br>
&nbsp;&nbsp;&nbsp;&nbsp;especially&nbsp;in&nbsp;regression.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`min_samples_leaf`&nbsp;as&nbsp;the&nbsp;minimum&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`min_samples_leaf`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ceil(min_samples_leaf&nbsp;*&nbsp;n_samples)`&nbsp;are&nbsp;the&nbsp;minimum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;node.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Added&nbsp;float&nbsp;values&nbsp;for&nbsp;fractions.<br>
&nbsp;<br>
min_weight_fraction_leaf&nbsp;:&nbsp;float,&nbsp;optional&nbsp;(default=0.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;weighted&nbsp;fraction&nbsp;of&nbsp;the&nbsp;sum&nbsp;total&nbsp;of&nbsp;weights&nbsp;(of&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;input&nbsp;samples)&nbsp;required&nbsp;to&nbsp;be&nbsp;at&nbsp;a&nbsp;leaf&nbsp;node.&nbsp;Samples&nbsp;have<br>
&nbsp;&nbsp;&nbsp;&nbsp;equal&nbsp;weight&nbsp;when&nbsp;sample_weight&nbsp;is&nbsp;not&nbsp;provided.<br>
&nbsp;<br>
max_features&nbsp;:&nbsp;int,&nbsp;float,&nbsp;string&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;to&nbsp;consider&nbsp;when&nbsp;looking&nbsp;for&nbsp;the&nbsp;best&nbsp;split:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`max_features`&nbsp;features&nbsp;at&nbsp;each&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`max_features`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`int(max_features&nbsp;*&nbsp;n_features)`&nbsp;features&nbsp;are&nbsp;considered&nbsp;at&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"auto",&nbsp;then&nbsp;`max_features=n_features`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"sqrt",&nbsp;then&nbsp;`max_features=sqrt(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"log2",&nbsp;then&nbsp;`max_features=log2(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;None,&nbsp;then&nbsp;`max_features=n_features`.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Note:&nbsp;the&nbsp;search&nbsp;for&nbsp;a&nbsp;split&nbsp;does&nbsp;not&nbsp;stop&nbsp;until&nbsp;at&nbsp;least&nbsp;one<br>
&nbsp;&nbsp;&nbsp;&nbsp;valid&nbsp;partition&nbsp;of&nbsp;the&nbsp;node&nbsp;samples&nbsp;is&nbsp;found,&nbsp;even&nbsp;if&nbsp;it&nbsp;requires&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;effectively&nbsp;inspect&nbsp;more&nbsp;than&nbsp;``max_features``&nbsp;features.<br>
&nbsp;<br>
random_state&nbsp;:&nbsp;int,&nbsp;RandomState&nbsp;instance&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;int,&nbsp;random_state&nbsp;is&nbsp;the&nbsp;seed&nbsp;used&nbsp;by&nbsp;the&nbsp;random&nbsp;number&nbsp;generator;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;RandomState&nbsp;instance,&nbsp;random_state&nbsp;is&nbsp;the&nbsp;random&nbsp;number&nbsp;generator;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None,&nbsp;the&nbsp;random&nbsp;number&nbsp;generator&nbsp;is&nbsp;the&nbsp;RandomState&nbsp;instance&nbsp;used<br>
&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;`np.random`.<br>
&nbsp;<br>
max_leaf_nodes&nbsp;:&nbsp;int&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Grow&nbsp;a&nbsp;tree&nbsp;with&nbsp;``max_leaf_nodes``&nbsp;in&nbsp;best-first&nbsp;fashion.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Best&nbsp;nodes&nbsp;are&nbsp;defined&nbsp;as&nbsp;relative&nbsp;reduction&nbsp;in&nbsp;impurity.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None&nbsp;then&nbsp;unlimited&nbsp;number&nbsp;of&nbsp;leaf&nbsp;nodes.<br>
&nbsp;<br>
min_impurity_decrease&nbsp;:&nbsp;float,&nbsp;optional&nbsp;(default=0.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;node&nbsp;will&nbsp;be&nbsp;split&nbsp;if&nbsp;this&nbsp;split&nbsp;induces&nbsp;a&nbsp;decrease&nbsp;of&nbsp;the&nbsp;impurity<br>
&nbsp;&nbsp;&nbsp;&nbsp;greater&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;this&nbsp;value.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;weighted&nbsp;impurity&nbsp;decrease&nbsp;equation&nbsp;is&nbsp;the&nbsp;following::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;N_t&nbsp;/&nbsp;N&nbsp;*&nbsp;(impurity&nbsp;-&nbsp;N_t_R&nbsp;/&nbsp;N_t&nbsp;*&nbsp;right_impurity<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;N_t_L&nbsp;/&nbsp;N_t&nbsp;*&nbsp;left_impurity)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;where&nbsp;``N``&nbsp;is&nbsp;the&nbsp;total&nbsp;number&nbsp;of&nbsp;samples,&nbsp;``N_t``&nbsp;is&nbsp;the&nbsp;number&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;samples&nbsp;at&nbsp;the&nbsp;current&nbsp;node,&nbsp;``N_t_L``&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;left&nbsp;child,&nbsp;and&nbsp;``N_t_R``&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;right&nbsp;child.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;``N``,&nbsp;``N_t``,&nbsp;``N_t_R``&nbsp;and&nbsp;``N_t_L``&nbsp;all&nbsp;refer&nbsp;to&nbsp;the&nbsp;weighted&nbsp;sum,<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;``sample_weight``&nbsp;is&nbsp;passed.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionadded::&nbsp;0.19<br>
&nbsp;<br>
min_impurity_split&nbsp;:&nbsp;float,&nbsp;(default=1e-7)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Threshold&nbsp;for&nbsp;early&nbsp;stopping&nbsp;in&nbsp;tree&nbsp;growth.&nbsp;A&nbsp;node&nbsp;will&nbsp;split<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;its&nbsp;impurity&nbsp;is&nbsp;above&nbsp;the&nbsp;threshold,&nbsp;otherwise&nbsp;it&nbsp;is&nbsp;a&nbsp;leaf.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;deprecated::&nbsp;0.19<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_split``&nbsp;has&nbsp;been&nbsp;deprecated&nbsp;in&nbsp;favor&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_decrease``&nbsp;in&nbsp;0.19.&nbsp;The&nbsp;default&nbsp;value&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_split``&nbsp;will&nbsp;change&nbsp;from&nbsp;1e-7&nbsp;to&nbsp;0&nbsp;in&nbsp;0.23&nbsp;and&nbsp;it<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;be&nbsp;removed&nbsp;in&nbsp;0.25.&nbsp;Use&nbsp;``min_impurity_decrease``&nbsp;instead.<br>
&nbsp;<br>
presort&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;presort&nbsp;the&nbsp;data&nbsp;to&nbsp;speed&nbsp;up&nbsp;the&nbsp;finding&nbsp;of&nbsp;best&nbsp;splits&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;fitting.&nbsp;For&nbsp;the&nbsp;default&nbsp;settings&nbsp;of&nbsp;a&nbsp;decision&nbsp;tree&nbsp;on&nbsp;large<br>
&nbsp;&nbsp;&nbsp;&nbsp;datasets,&nbsp;setting&nbsp;this&nbsp;to&nbsp;true&nbsp;may&nbsp;slow&nbsp;down&nbsp;the&nbsp;training&nbsp;process.<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;using&nbsp;either&nbsp;a&nbsp;smaller&nbsp;dataset&nbsp;or&nbsp;a&nbsp;restricted&nbsp;depth,&nbsp;this&nbsp;may<br>
&nbsp;&nbsp;&nbsp;&nbsp;speed&nbsp;up&nbsp;the&nbsp;training.<br>
&nbsp;<br>
Attributes<br>
----------<br>
feature_importances_&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;feature&nbsp;importances.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;higher,&nbsp;the&nbsp;more&nbsp;important&nbsp;the&nbsp;feature.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;importance&nbsp;of&nbsp;a&nbsp;feature&nbsp;is&nbsp;computed&nbsp;as&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;(normalized)&nbsp;total&nbsp;reduction&nbsp;of&nbsp;the&nbsp;criterion&nbsp;brought<br>
&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;that&nbsp;feature.&nbsp;It&nbsp;is&nbsp;also&nbsp;known&nbsp;as&nbsp;the&nbsp;Gini&nbsp;importance&nbsp;[4]_.<br>
&nbsp;<br>
max_features_&nbsp;:&nbsp;int,<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;inferred&nbsp;value&nbsp;of&nbsp;max_features.<br>
&nbsp;<br>
n_features_&nbsp;:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;when&nbsp;``fit``&nbsp;is&nbsp;performed.<br>
&nbsp;<br>
n_outputs_&nbsp;:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;outputs&nbsp;when&nbsp;``fit``&nbsp;is&nbsp;performed.<br>
&nbsp;<br>
tree_&nbsp;:&nbsp;Tree&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;underlying&nbsp;Tree&nbsp;object.&nbsp;Please&nbsp;refer&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``help(sklearn.tree._tree.Tree)``&nbsp;for&nbsp;attributes&nbsp;of&nbsp;Tree&nbsp;object&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;basic&nbsp;usage&nbsp;of&nbsp;these&nbsp;attributes.<br>
&nbsp;<br>
Notes<br>
-----<br>
The&nbsp;default&nbsp;values&nbsp;for&nbsp;the&nbsp;parameters&nbsp;controlling&nbsp;the&nbsp;size&nbsp;of&nbsp;the&nbsp;trees<br>
(e.g.&nbsp;``max_depth``,&nbsp;``min_samples_leaf``,&nbsp;etc.)&nbsp;lead&nbsp;to&nbsp;fully&nbsp;grown&nbsp;and<br>
unpruned&nbsp;trees&nbsp;which&nbsp;can&nbsp;potentially&nbsp;be&nbsp;very&nbsp;large&nbsp;on&nbsp;some&nbsp;data&nbsp;sets.&nbsp;To<br>
reduce&nbsp;memory&nbsp;consumption,&nbsp;the&nbsp;complexity&nbsp;and&nbsp;size&nbsp;of&nbsp;the&nbsp;trees&nbsp;should&nbsp;be<br>
controlled&nbsp;by&nbsp;setting&nbsp;those&nbsp;parameter&nbsp;values.<br>
&nbsp;<br>
The&nbsp;features&nbsp;are&nbsp;always&nbsp;randomly&nbsp;permuted&nbsp;at&nbsp;each&nbsp;split.&nbsp;Therefore,<br>
the&nbsp;best&nbsp;found&nbsp;split&nbsp;may&nbsp;vary,&nbsp;even&nbsp;with&nbsp;the&nbsp;same&nbsp;training&nbsp;data&nbsp;and<br>
``max_features=n_features``,&nbsp;if&nbsp;the&nbsp;improvement&nbsp;of&nbsp;the&nbsp;criterion&nbsp;is<br>
identical&nbsp;for&nbsp;several&nbsp;splits&nbsp;enumerated&nbsp;during&nbsp;the&nbsp;search&nbsp;of&nbsp;the&nbsp;best<br>
split.&nbsp;To&nbsp;obtain&nbsp;a&nbsp;deterministic&nbsp;behaviour&nbsp;during&nbsp;fitting,<br>
``random_state``&nbsp;has&nbsp;to&nbsp;be&nbsp;fixed.<br>
&nbsp;<br>
See&nbsp;also<br>
--------<br>
<a href="#DecisionTreeClassifier">DecisionTreeClassifier</a><br>
&nbsp;<br>
References<br>
----------<br>
&nbsp;<br>
..&nbsp;[1]&nbsp;https://en.wikipedia.org/wiki/Decision_tree_learning<br>
&nbsp;<br>
..&nbsp;[2]&nbsp;L.&nbsp;Breiman,&nbsp;J.&nbsp;Friedman,&nbsp;R.&nbsp;Olshen,&nbsp;and&nbsp;C.&nbsp;Stone,&nbsp;"Classification<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;Regression&nbsp;Trees",&nbsp;Wadsworth,&nbsp;Belmont,&nbsp;CA,&nbsp;1984.<br>
&nbsp;<br>
..&nbsp;[3]&nbsp;T.&nbsp;Hastie,&nbsp;R.&nbsp;Tibshirani&nbsp;and&nbsp;J.&nbsp;Friedman.&nbsp;"Elements&nbsp;of&nbsp;Statistical<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Learning",&nbsp;Springer,&nbsp;2009.<br>
&nbsp;<br>
..&nbsp;[4]&nbsp;L.&nbsp;Breiman,&nbsp;and&nbsp;A.&nbsp;Cutler,&nbsp;"Random&nbsp;Forests",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm<br>
&nbsp;<br>
Examples<br>
--------<br>
&gt;&gt;&gt;&nbsp;from&nbsp;sklearn.datasets&nbsp;import&nbsp;load_boston<br>
&gt;&gt;&gt;&nbsp;from&nbsp;sklearn.model_selection&nbsp;import&nbsp;cross_val_score<br>
&gt;&gt;&gt;&nbsp;from&nbsp;sklearn.tree&nbsp;import&nbsp;<a href="#DecisionTreeRegressor">DecisionTreeRegressor</a><br>
&gt;&gt;&gt;&nbsp;boston&nbsp;=&nbsp;load_boston()<br>
&gt;&gt;&gt;&nbsp;regressor&nbsp;=&nbsp;<a href="#DecisionTreeRegressor">DecisionTreeRegressor</a>(random_state=0)<br>
&gt;&gt;&gt;&nbsp;cross_val_score(regressor,&nbsp;boston.data,&nbsp;boston.target,&nbsp;cv=10)<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;doctest:&nbsp;+SKIP<br>
...<br>
array([&nbsp;0.61...,&nbsp;0.57...,&nbsp;-0.34...,&nbsp;0.41...,&nbsp;0.75...,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.07...,&nbsp;0.29...,&nbsp;0.33...,&nbsp;-1.42...,&nbsp;-1.77...])<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="sklearn.tree.tree.html#DecisionTreeRegressor">DecisionTreeRegressor</a></dd>
<dd><a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a></dd>
<dd>abc.NewBase</dd>
<dd><a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a></dd>
<dd><a href="sklearn.base.html#RegressorMixin">sklearn.base.RegressorMixin</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="DecisionTreeRegressor-__init__"><strong>__init__</strong></a>(self, criterion='mse', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, presort=False)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="DecisionTreeRegressor-fit"><strong>fit</strong></a>(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)</dt><dd><tt>Build&nbsp;a&nbsp;decision&nbsp;tree&nbsp;regressor&nbsp;from&nbsp;the&nbsp;training&nbsp;set&nbsp;(X,&nbsp;y).<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;training&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csc_matrix``.<br>
&nbsp;<br>
y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;[n_samples,&nbsp;n_outputs]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;target&nbsp;values&nbsp;(real&nbsp;numbers).&nbsp;Use&nbsp;``dtype=np.float64``&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;``order='C'``&nbsp;for&nbsp;maximum&nbsp;efficiency.<br>
&nbsp;<br>
sample_weight&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sample&nbsp;weights.&nbsp;If&nbsp;None,&nbsp;then&nbsp;samples&nbsp;are&nbsp;equally&nbsp;weighted.&nbsp;Splits<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;would&nbsp;create&nbsp;child&nbsp;nodes&nbsp;with&nbsp;net&nbsp;zero&nbsp;or&nbsp;negative&nbsp;weight&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;ignored&nbsp;while&nbsp;searching&nbsp;for&nbsp;a&nbsp;split&nbsp;in&nbsp;each&nbsp;node.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
X_idx_sorted&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features],&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;indexes&nbsp;of&nbsp;the&nbsp;sorted&nbsp;training&nbsp;input&nbsp;samples.&nbsp;If&nbsp;many&nbsp;tree<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;grown&nbsp;on&nbsp;the&nbsp;same&nbsp;dataset,&nbsp;this&nbsp;allows&nbsp;the&nbsp;ordering&nbsp;to&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;between&nbsp;trees.&nbsp;If&nbsp;None,&nbsp;the&nbsp;data&nbsp;will&nbsp;be&nbsp;sorted&nbsp;here.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;to&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
self&nbsp;:&nbsp;object</tt></dd></dl>

<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>__abstractmethods__</strong> = frozenset()</dl>

<hr>
Methods inherited from <a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>:<br>
<dl><dt><a name="DecisionTreeRegressor-apply"><strong>apply</strong></a>(self, X, check_input=True)</dt><dd><tt>Returns&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;leaf&nbsp;that&nbsp;each&nbsp;sample&nbsp;is&nbsp;predicted&nbsp;as.<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.17<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array_like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
X_leaves&nbsp;:&nbsp;array_like,&nbsp;shape&nbsp;=&nbsp;[n_samples,]<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;each&nbsp;datapoint&nbsp;x&nbsp;in&nbsp;X,&nbsp;return&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;leaf&nbsp;x<br>
&nbsp;&nbsp;&nbsp;&nbsp;ends&nbsp;up&nbsp;in.&nbsp;Leaves&nbsp;are&nbsp;numbered&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;``[0;&nbsp;self.<strong>tree_</strong>.node_count)``,&nbsp;possibly&nbsp;with&nbsp;gaps&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;numbering.</tt></dd></dl>

<dl><dt><a name="DecisionTreeRegressor-decision_path"><strong>decision_path</strong></a>(self, X, check_input=True)</dt><dd><tt>Return&nbsp;the&nbsp;decision&nbsp;path&nbsp;in&nbsp;the&nbsp;tree<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.18<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array_like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
indicator&nbsp;:&nbsp;sparse&nbsp;csr&nbsp;array,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_nodes]<br>
&nbsp;&nbsp;&nbsp;&nbsp;Return&nbsp;a&nbsp;node&nbsp;indicator&nbsp;matrix&nbsp;where&nbsp;non&nbsp;zero&nbsp;elements<br>
&nbsp;&nbsp;&nbsp;&nbsp;indicates&nbsp;that&nbsp;the&nbsp;samples&nbsp;goes&nbsp;through&nbsp;the&nbsp;nodes.</tt></dd></dl>

<dl><dt><a name="DecisionTreeRegressor-predict"><strong>predict</strong></a>(self, X, check_input=True)</dt><dd><tt>Predict&nbsp;class&nbsp;or&nbsp;regression&nbsp;value&nbsp;for&nbsp;X.<br>
&nbsp;<br>
For&nbsp;a&nbsp;classification&nbsp;model,&nbsp;the&nbsp;predicted&nbsp;class&nbsp;for&nbsp;each&nbsp;sample&nbsp;in&nbsp;X&nbsp;is<br>
returned.&nbsp;For&nbsp;a&nbsp;regression&nbsp;model,&nbsp;the&nbsp;predicted&nbsp;value&nbsp;based&nbsp;on&nbsp;X&nbsp;is<br>
returned.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
y&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;[n_samples,&nbsp;n_outputs]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;predicted&nbsp;classes,&nbsp;or&nbsp;the&nbsp;predict&nbsp;values.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>:<br>
<dl><dt><strong>feature_importances_</strong></dt>
<dd><tt>Return&nbsp;the&nbsp;feature&nbsp;importances.<br>
&nbsp;<br>
The&nbsp;importance&nbsp;of&nbsp;a&nbsp;feature&nbsp;is&nbsp;computed&nbsp;as&nbsp;the&nbsp;(normalized)&nbsp;total<br>
reduction&nbsp;of&nbsp;the&nbsp;criterion&nbsp;brought&nbsp;by&nbsp;that&nbsp;feature.<br>
It&nbsp;is&nbsp;also&nbsp;known&nbsp;as&nbsp;the&nbsp;Gini&nbsp;importance.<br>
&nbsp;<br>
Returns<br>
-------<br>
feature_importances_&nbsp;:&nbsp;array,&nbsp;shape&nbsp;=&nbsp;[n_features]</tt></dd>
</dl>
<hr>
Methods inherited from <a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a>:<br>
<dl><dt><a name="DecisionTreeRegressor-__getstate__"><strong>__getstate__</strong></a>(self)</dt></dl>

<dl><dt><a name="DecisionTreeRegressor-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="DecisionTreeRegressor-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="DecisionTreeRegressor-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><tt>Get&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
Parameters<br>
----------<br>
deep&nbsp;:&nbsp;boolean,&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;True,&nbsp;will&nbsp;return&nbsp;the&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;contained&nbsp;subobjects&nbsp;that&nbsp;are&nbsp;estimators.<br>
&nbsp;<br>
Returns<br>
-------<br>
params&nbsp;:&nbsp;mapping&nbsp;of&nbsp;string&nbsp;to&nbsp;any<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;names&nbsp;mapped&nbsp;to&nbsp;their&nbsp;values.</tt></dd></dl>

<dl><dt><a name="DecisionTreeRegressor-set_params"><strong>set_params</strong></a>(self, **params)</dt><dd><tt>Set&nbsp;the&nbsp;parameters&nbsp;of&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
The&nbsp;method&nbsp;works&nbsp;on&nbsp;simple&nbsp;estimators&nbsp;as&nbsp;well&nbsp;as&nbsp;on&nbsp;nested&nbsp;objects<br>
(such&nbsp;as&nbsp;pipelines).&nbsp;The&nbsp;latter&nbsp;have&nbsp;parameters&nbsp;of&nbsp;the&nbsp;form<br>
``&lt;component&gt;__&lt;parameter&gt;``&nbsp;so&nbsp;that&nbsp;it's&nbsp;possible&nbsp;to&nbsp;update&nbsp;each<br>
component&nbsp;of&nbsp;a&nbsp;nested&nbsp;object.<br>
&nbsp;<br>
Returns<br>
-------<br>
self</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Methods inherited from <a href="sklearn.base.html#RegressorMixin">sklearn.base.RegressorMixin</a>:<br>
<dl><dt><a name="DecisionTreeRegressor-score"><strong>score</strong></a>(self, X, y, sample_weight=None)</dt><dd><tt>Returns&nbsp;the&nbsp;coefficient&nbsp;of&nbsp;determination&nbsp;R^2&nbsp;of&nbsp;the&nbsp;prediction.<br>
&nbsp;<br>
The&nbsp;coefficient&nbsp;R^2&nbsp;is&nbsp;defined&nbsp;as&nbsp;(1&nbsp;-&nbsp;u/v),&nbsp;where&nbsp;u&nbsp;is&nbsp;the&nbsp;residual<br>
sum&nbsp;of&nbsp;squares&nbsp;((y_true&nbsp;-&nbsp;y_pred)&nbsp;**&nbsp;2).sum()&nbsp;and&nbsp;v&nbsp;is&nbsp;the&nbsp;total<br>
sum&nbsp;of&nbsp;squares&nbsp;((y_true&nbsp;-&nbsp;y_true.mean())&nbsp;**&nbsp;2).sum().<br>
The&nbsp;best&nbsp;possible&nbsp;score&nbsp;is&nbsp;1.0&nbsp;and&nbsp;it&nbsp;can&nbsp;be&nbsp;negative&nbsp;(because&nbsp;the<br>
model&nbsp;can&nbsp;be&nbsp;arbitrarily&nbsp;worse).&nbsp;A&nbsp;constant&nbsp;model&nbsp;that&nbsp;always<br>
predicts&nbsp;the&nbsp;expected&nbsp;value&nbsp;of&nbsp;y,&nbsp;disregarding&nbsp;the&nbsp;input&nbsp;features,<br>
would&nbsp;get&nbsp;a&nbsp;R^2&nbsp;score&nbsp;of&nbsp;0.0.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;(n_samples,&nbsp;n_features)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Test&nbsp;samples.&nbsp;For&nbsp;some&nbsp;estimators&nbsp;this&nbsp;may&nbsp;be&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;precomputed&nbsp;kernel&nbsp;matrix&nbsp;instead,&nbsp;shape&nbsp;=&nbsp;(n_samples,<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_samples_fitted],&nbsp;where&nbsp;n_samples_fitted&nbsp;is&nbsp;the&nbsp;number&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;samples&nbsp;used&nbsp;in&nbsp;the&nbsp;fitting&nbsp;for&nbsp;the&nbsp;estimator.<br>
&nbsp;<br>
y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;(n_samples)&nbsp;or&nbsp;(n_samples,&nbsp;n_outputs)<br>
&nbsp;&nbsp;&nbsp;&nbsp;True&nbsp;values&nbsp;for&nbsp;X.<br>
&nbsp;<br>
sample_weight&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples],&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sample&nbsp;weights.<br>
&nbsp;<br>
Returns<br>
-------<br>
score&nbsp;:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;R^2&nbsp;of&nbsp;self.<a href="#DecisionTreeRegressor-predict">predict</a>(X)&nbsp;wrt.&nbsp;y.</tt></dd></dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="ExtraTreeClassifier">class <strong>ExtraTreeClassifier</strong></a>(<a href="sklearn.tree.tree.html#DecisionTreeClassifier">DecisionTreeClassifier</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>An&nbsp;extremely&nbsp;randomized&nbsp;tree&nbsp;classifier.<br>
&nbsp;<br>
Extra-trees&nbsp;differ&nbsp;from&nbsp;classic&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;way&nbsp;they&nbsp;are&nbsp;built.<br>
When&nbsp;looking&nbsp;for&nbsp;the&nbsp;best&nbsp;split&nbsp;to&nbsp;separate&nbsp;the&nbsp;samples&nbsp;of&nbsp;a&nbsp;node&nbsp;into&nbsp;two<br>
groups,&nbsp;random&nbsp;splits&nbsp;are&nbsp;drawn&nbsp;for&nbsp;each&nbsp;of&nbsp;the&nbsp;`max_features`&nbsp;randomly<br>
selected&nbsp;features&nbsp;and&nbsp;the&nbsp;best&nbsp;split&nbsp;among&nbsp;those&nbsp;is&nbsp;chosen.&nbsp;When<br>
`max_features`&nbsp;is&nbsp;set&nbsp;1,&nbsp;this&nbsp;amounts&nbsp;to&nbsp;building&nbsp;a&nbsp;totally&nbsp;random<br>
decision&nbsp;tree.<br>
&nbsp;<br>
Warning:&nbsp;Extra-trees&nbsp;should&nbsp;only&nbsp;be&nbsp;used&nbsp;within&nbsp;ensemble&nbsp;methods.<br>
&nbsp;<br>
Read&nbsp;more&nbsp;in&nbsp;the&nbsp;:ref:`User&nbsp;Guide&nbsp;&lt;tree&gt;`.<br>
&nbsp;<br>
Parameters<br>
----------<br>
criterion&nbsp;:&nbsp;string,&nbsp;optional&nbsp;(default="gini")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;function&nbsp;to&nbsp;measure&nbsp;the&nbsp;quality&nbsp;of&nbsp;a&nbsp;split.&nbsp;Supported&nbsp;criteria&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;"gini"&nbsp;for&nbsp;the&nbsp;Gini&nbsp;impurity&nbsp;and&nbsp;"entropy"&nbsp;for&nbsp;the&nbsp;information&nbsp;gain.<br>
&nbsp;<br>
splitter&nbsp;:&nbsp;string,&nbsp;optional&nbsp;(default="random")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;strategy&nbsp;used&nbsp;to&nbsp;choose&nbsp;the&nbsp;split&nbsp;at&nbsp;each&nbsp;node.&nbsp;Supported<br>
&nbsp;&nbsp;&nbsp;&nbsp;strategies&nbsp;are&nbsp;"best"&nbsp;to&nbsp;choose&nbsp;the&nbsp;best&nbsp;split&nbsp;and&nbsp;"random"&nbsp;to&nbsp;choose<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;best&nbsp;random&nbsp;split.<br>
&nbsp;<br>
max_depth&nbsp;:&nbsp;int&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree.&nbsp;If&nbsp;None,&nbsp;then&nbsp;nodes&nbsp;are&nbsp;expanded&nbsp;until<br>
&nbsp;&nbsp;&nbsp;&nbsp;all&nbsp;leaves&nbsp;are&nbsp;pure&nbsp;or&nbsp;until&nbsp;all&nbsp;leaves&nbsp;contain&nbsp;less&nbsp;than<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;samples.<br>
&nbsp;<br>
min_samples_split&nbsp;:&nbsp;int,&nbsp;float,&nbsp;optional&nbsp;(default=2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`min_samples_split`&nbsp;as&nbsp;the&nbsp;minimum&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`min_samples_split`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ceil(min_samples_split&nbsp;*&nbsp;n_samples)`&nbsp;are&nbsp;the&nbsp;minimum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;split.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Added&nbsp;float&nbsp;values&nbsp;for&nbsp;fractions.<br>
&nbsp;<br>
min_samples_leaf&nbsp;:&nbsp;int,&nbsp;float,&nbsp;optional&nbsp;(default=1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;be&nbsp;at&nbsp;a&nbsp;leaf&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;split&nbsp;point&nbsp;at&nbsp;any&nbsp;depth&nbsp;will&nbsp;only&nbsp;be&nbsp;considered&nbsp;if&nbsp;it&nbsp;leaves&nbsp;at<br>
&nbsp;&nbsp;&nbsp;&nbsp;least&nbsp;``min_samples_leaf``&nbsp;training&nbsp;samples&nbsp;in&nbsp;each&nbsp;of&nbsp;the&nbsp;left&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;right&nbsp;branches.&nbsp;&nbsp;This&nbsp;may&nbsp;have&nbsp;the&nbsp;effect&nbsp;of&nbsp;smoothing&nbsp;the&nbsp;model,<br>
&nbsp;&nbsp;&nbsp;&nbsp;especially&nbsp;in&nbsp;regression.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`min_samples_leaf`&nbsp;as&nbsp;the&nbsp;minimum&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`min_samples_leaf`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ceil(min_samples_leaf&nbsp;*&nbsp;n_samples)`&nbsp;are&nbsp;the&nbsp;minimum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;node.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Added&nbsp;float&nbsp;values&nbsp;for&nbsp;fractions.<br>
&nbsp;<br>
min_weight_fraction_leaf&nbsp;:&nbsp;float,&nbsp;optional&nbsp;(default=0.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;weighted&nbsp;fraction&nbsp;of&nbsp;the&nbsp;sum&nbsp;total&nbsp;of&nbsp;weights&nbsp;(of&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;input&nbsp;samples)&nbsp;required&nbsp;to&nbsp;be&nbsp;at&nbsp;a&nbsp;leaf&nbsp;node.&nbsp;Samples&nbsp;have<br>
&nbsp;&nbsp;&nbsp;&nbsp;equal&nbsp;weight&nbsp;when&nbsp;sample_weight&nbsp;is&nbsp;not&nbsp;provided.<br>
&nbsp;<br>
max_features&nbsp;:&nbsp;int,&nbsp;float,&nbsp;string&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default="auto")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;to&nbsp;consider&nbsp;when&nbsp;looking&nbsp;for&nbsp;the&nbsp;best&nbsp;split:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`max_features`&nbsp;features&nbsp;at&nbsp;each&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`max_features`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`int(max_features&nbsp;*&nbsp;n_features)`&nbsp;features&nbsp;are&nbsp;considered&nbsp;at&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"auto",&nbsp;then&nbsp;`max_features=sqrt(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"sqrt",&nbsp;then&nbsp;`max_features=sqrt(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"log2",&nbsp;then&nbsp;`max_features=log2(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;None,&nbsp;then&nbsp;`max_features=n_features`.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Note:&nbsp;the&nbsp;search&nbsp;for&nbsp;a&nbsp;split&nbsp;does&nbsp;not&nbsp;stop&nbsp;until&nbsp;at&nbsp;least&nbsp;one<br>
&nbsp;&nbsp;&nbsp;&nbsp;valid&nbsp;partition&nbsp;of&nbsp;the&nbsp;node&nbsp;samples&nbsp;is&nbsp;found,&nbsp;even&nbsp;if&nbsp;it&nbsp;requires&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;effectively&nbsp;inspect&nbsp;more&nbsp;than&nbsp;``max_features``&nbsp;features.<br>
&nbsp;<br>
random_state&nbsp;:&nbsp;int,&nbsp;RandomState&nbsp;instance&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;int,&nbsp;random_state&nbsp;is&nbsp;the&nbsp;seed&nbsp;used&nbsp;by&nbsp;the&nbsp;random&nbsp;number&nbsp;generator;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;RandomState&nbsp;instance,&nbsp;random_state&nbsp;is&nbsp;the&nbsp;random&nbsp;number&nbsp;generator;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None,&nbsp;the&nbsp;random&nbsp;number&nbsp;generator&nbsp;is&nbsp;the&nbsp;RandomState&nbsp;instance&nbsp;used<br>
&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;`np.random`.<br>
&nbsp;<br>
max_leaf_nodes&nbsp;:&nbsp;int&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Grow&nbsp;a&nbsp;tree&nbsp;with&nbsp;``max_leaf_nodes``&nbsp;in&nbsp;best-first&nbsp;fashion.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Best&nbsp;nodes&nbsp;are&nbsp;defined&nbsp;as&nbsp;relative&nbsp;reduction&nbsp;in&nbsp;impurity.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None&nbsp;then&nbsp;unlimited&nbsp;number&nbsp;of&nbsp;leaf&nbsp;nodes.<br>
&nbsp;<br>
min_impurity_decrease&nbsp;:&nbsp;float,&nbsp;optional&nbsp;(default=0.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;node&nbsp;will&nbsp;be&nbsp;split&nbsp;if&nbsp;this&nbsp;split&nbsp;induces&nbsp;a&nbsp;decrease&nbsp;of&nbsp;the&nbsp;impurity<br>
&nbsp;&nbsp;&nbsp;&nbsp;greater&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;this&nbsp;value.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;weighted&nbsp;impurity&nbsp;decrease&nbsp;equation&nbsp;is&nbsp;the&nbsp;following::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;N_t&nbsp;/&nbsp;N&nbsp;*&nbsp;(impurity&nbsp;-&nbsp;N_t_R&nbsp;/&nbsp;N_t&nbsp;*&nbsp;right_impurity<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;N_t_L&nbsp;/&nbsp;N_t&nbsp;*&nbsp;left_impurity)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;where&nbsp;``N``&nbsp;is&nbsp;the&nbsp;total&nbsp;number&nbsp;of&nbsp;samples,&nbsp;``N_t``&nbsp;is&nbsp;the&nbsp;number&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;samples&nbsp;at&nbsp;the&nbsp;current&nbsp;node,&nbsp;``N_t_L``&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;left&nbsp;child,&nbsp;and&nbsp;``N_t_R``&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;right&nbsp;child.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;``N``,&nbsp;``N_t``,&nbsp;``N_t_R``&nbsp;and&nbsp;``N_t_L``&nbsp;all&nbsp;refer&nbsp;to&nbsp;the&nbsp;weighted&nbsp;sum,<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;``sample_weight``&nbsp;is&nbsp;passed.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionadded::&nbsp;0.19<br>
&nbsp;<br>
min_impurity_split&nbsp;:&nbsp;float,&nbsp;(default=1e-7)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Threshold&nbsp;for&nbsp;early&nbsp;stopping&nbsp;in&nbsp;tree&nbsp;growth.&nbsp;A&nbsp;node&nbsp;will&nbsp;split<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;its&nbsp;impurity&nbsp;is&nbsp;above&nbsp;the&nbsp;threshold,&nbsp;otherwise&nbsp;it&nbsp;is&nbsp;a&nbsp;leaf.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;deprecated::&nbsp;0.19<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_split``&nbsp;has&nbsp;been&nbsp;deprecated&nbsp;in&nbsp;favor&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_decrease``&nbsp;in&nbsp;0.19.&nbsp;The&nbsp;default&nbsp;value&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_split``&nbsp;will&nbsp;change&nbsp;from&nbsp;1e-7&nbsp;to&nbsp;0&nbsp;in&nbsp;0.23&nbsp;and&nbsp;it<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;be&nbsp;removed&nbsp;in&nbsp;0.25.&nbsp;Use&nbsp;``min_impurity_decrease``&nbsp;instead.<br>
&nbsp;<br>
class_weight&nbsp;:&nbsp;dict,&nbsp;list&nbsp;of&nbsp;dicts,&nbsp;"balanced"&nbsp;or&nbsp;None,&nbsp;default=None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Weights&nbsp;associated&nbsp;with&nbsp;classes&nbsp;in&nbsp;the&nbsp;form&nbsp;``{class_label:&nbsp;weight}``.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;not&nbsp;given,&nbsp;all&nbsp;classes&nbsp;are&nbsp;supposed&nbsp;to&nbsp;have&nbsp;weight&nbsp;one.&nbsp;For<br>
&nbsp;&nbsp;&nbsp;&nbsp;multi-output&nbsp;problems,&nbsp;a&nbsp;list&nbsp;of&nbsp;dicts&nbsp;can&nbsp;be&nbsp;provided&nbsp;in&nbsp;the&nbsp;same<br>
&nbsp;&nbsp;&nbsp;&nbsp;order&nbsp;as&nbsp;the&nbsp;columns&nbsp;of&nbsp;y.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Note&nbsp;that&nbsp;for&nbsp;multioutput&nbsp;(including&nbsp;multilabel)&nbsp;weights&nbsp;should&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;defined&nbsp;for&nbsp;each&nbsp;class&nbsp;of&nbsp;every&nbsp;column&nbsp;in&nbsp;its&nbsp;own&nbsp;dict.&nbsp;For&nbsp;example,<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;four-class&nbsp;multilabel&nbsp;classification&nbsp;weights&nbsp;should&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;[{0:&nbsp;1,&nbsp;1:&nbsp;1},&nbsp;{0:&nbsp;1,&nbsp;1:&nbsp;5},&nbsp;{0:&nbsp;1,&nbsp;1:&nbsp;1},&nbsp;{0:&nbsp;1,&nbsp;1:&nbsp;1}]&nbsp;instead&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;[{1:1},&nbsp;{2:5},&nbsp;{3:1},&nbsp;{4:1}].<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;"balanced"&nbsp;mode&nbsp;uses&nbsp;the&nbsp;values&nbsp;of&nbsp;y&nbsp;to&nbsp;automatically&nbsp;adjust<br>
&nbsp;&nbsp;&nbsp;&nbsp;weights&nbsp;inversely&nbsp;proportional&nbsp;to&nbsp;class&nbsp;frequencies&nbsp;in&nbsp;the&nbsp;input&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;as&nbsp;``n_samples&nbsp;/&nbsp;(n_classes&nbsp;*&nbsp;np.bincount(y))``<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;multi-output,&nbsp;the&nbsp;weights&nbsp;of&nbsp;each&nbsp;column&nbsp;of&nbsp;y&nbsp;will&nbsp;be&nbsp;multiplied.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Note&nbsp;that&nbsp;these&nbsp;weights&nbsp;will&nbsp;be&nbsp;multiplied&nbsp;with&nbsp;sample_weight&nbsp;(passed<br>
&nbsp;&nbsp;&nbsp;&nbsp;through&nbsp;the&nbsp;fit&nbsp;method)&nbsp;if&nbsp;sample_weight&nbsp;is&nbsp;specified.<br>
&nbsp;<br>
See&nbsp;also<br>
--------<br>
<a href="#ExtraTreeRegressor">ExtraTreeRegressor</a>,&nbsp;sklearn.ensemble.ExtraTreesClassifier,<br>
sklearn.ensemble.ExtraTreesRegressor<br>
&nbsp;<br>
Notes<br>
-----<br>
The&nbsp;default&nbsp;values&nbsp;for&nbsp;the&nbsp;parameters&nbsp;controlling&nbsp;the&nbsp;size&nbsp;of&nbsp;the&nbsp;trees<br>
(e.g.&nbsp;``max_depth``,&nbsp;``min_samples_leaf``,&nbsp;etc.)&nbsp;lead&nbsp;to&nbsp;fully&nbsp;grown&nbsp;and<br>
unpruned&nbsp;trees&nbsp;which&nbsp;can&nbsp;potentially&nbsp;be&nbsp;very&nbsp;large&nbsp;on&nbsp;some&nbsp;data&nbsp;sets.&nbsp;To<br>
reduce&nbsp;memory&nbsp;consumption,&nbsp;the&nbsp;complexity&nbsp;and&nbsp;size&nbsp;of&nbsp;the&nbsp;trees&nbsp;should&nbsp;be<br>
controlled&nbsp;by&nbsp;setting&nbsp;those&nbsp;parameter&nbsp;values.<br>
&nbsp;<br>
References<br>
----------<br>
&nbsp;<br>
..&nbsp;[1]&nbsp;P.&nbsp;Geurts,&nbsp;D.&nbsp;Ernst.,&nbsp;and&nbsp;L.&nbsp;Wehenkel,&nbsp;"Extremely&nbsp;randomized&nbsp;trees",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Machine&nbsp;Learning,&nbsp;63(1),&nbsp;3-42,&nbsp;2006.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="sklearn.tree.tree.html#ExtraTreeClassifier">ExtraTreeClassifier</a></dd>
<dd><a href="sklearn.tree.tree.html#DecisionTreeClassifier">DecisionTreeClassifier</a></dd>
<dd><a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a></dd>
<dd>abc.NewBase</dd>
<dd><a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a></dd>
<dd><a href="sklearn.base.html#ClassifierMixin">sklearn.base.ClassifierMixin</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="ExtraTreeClassifier-__init__"><strong>__init__</strong></a>(self, criterion='gini', splitter='random', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>__abstractmethods__</strong> = frozenset()</dl>

<hr>
Methods inherited from <a href="sklearn.tree.tree.html#DecisionTreeClassifier">DecisionTreeClassifier</a>:<br>
<dl><dt><a name="ExtraTreeClassifier-fit"><strong>fit</strong></a>(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)</dt><dd><tt>Build&nbsp;a&nbsp;decision&nbsp;tree&nbsp;classifier&nbsp;from&nbsp;the&nbsp;training&nbsp;set&nbsp;(X,&nbsp;y).<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;training&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csc_matrix``.<br>
&nbsp;<br>
y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;[n_samples,&nbsp;n_outputs]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;target&nbsp;values&nbsp;(class&nbsp;labels)&nbsp;as&nbsp;integers&nbsp;or&nbsp;strings.<br>
&nbsp;<br>
sample_weight&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sample&nbsp;weights.&nbsp;If&nbsp;None,&nbsp;then&nbsp;samples&nbsp;are&nbsp;equally&nbsp;weighted.&nbsp;Splits<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;would&nbsp;create&nbsp;child&nbsp;nodes&nbsp;with&nbsp;net&nbsp;zero&nbsp;or&nbsp;negative&nbsp;weight&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;ignored&nbsp;while&nbsp;searching&nbsp;for&nbsp;a&nbsp;split&nbsp;in&nbsp;each&nbsp;node.&nbsp;Splits&nbsp;are&nbsp;also<br>
&nbsp;&nbsp;&nbsp;&nbsp;ignored&nbsp;if&nbsp;they&nbsp;would&nbsp;result&nbsp;in&nbsp;any&nbsp;single&nbsp;class&nbsp;carrying&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;negative&nbsp;weight&nbsp;in&nbsp;either&nbsp;child&nbsp;node.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
X_idx_sorted&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features],&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;indexes&nbsp;of&nbsp;the&nbsp;sorted&nbsp;training&nbsp;input&nbsp;samples.&nbsp;If&nbsp;many&nbsp;tree<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;grown&nbsp;on&nbsp;the&nbsp;same&nbsp;dataset,&nbsp;this&nbsp;allows&nbsp;the&nbsp;ordering&nbsp;to&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;between&nbsp;trees.&nbsp;If&nbsp;None,&nbsp;the&nbsp;data&nbsp;will&nbsp;be&nbsp;sorted&nbsp;here.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;to&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
self&nbsp;:&nbsp;object</tt></dd></dl>

<dl><dt><a name="ExtraTreeClassifier-predict_log_proba"><strong>predict_log_proba</strong></a>(self, X)</dt><dd><tt>Predict&nbsp;class&nbsp;log-probabilities&nbsp;of&nbsp;the&nbsp;input&nbsp;samples&nbsp;X.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
Returns<br>
-------<br>
p&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_classes],&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;n_outputs<br>
&nbsp;&nbsp;&nbsp;&nbsp;such&nbsp;arrays&nbsp;if&nbsp;n_outputs&nbsp;&gt;&nbsp;1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;class&nbsp;log-probabilities&nbsp;of&nbsp;the&nbsp;input&nbsp;samples.&nbsp;The&nbsp;order&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes&nbsp;corresponds&nbsp;to&nbsp;that&nbsp;in&nbsp;the&nbsp;attribute&nbsp;`classes_`.</tt></dd></dl>

<dl><dt><a name="ExtraTreeClassifier-predict_proba"><strong>predict_proba</strong></a>(self, X, check_input=True)</dt><dd><tt>Predict&nbsp;class&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;input&nbsp;samples&nbsp;X.<br>
&nbsp;<br>
The&nbsp;predicted&nbsp;class&nbsp;probability&nbsp;is&nbsp;the&nbsp;fraction&nbsp;of&nbsp;samples&nbsp;of&nbsp;the&nbsp;same<br>
class&nbsp;in&nbsp;a&nbsp;leaf.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;bool<br>
&nbsp;&nbsp;&nbsp;&nbsp;Run&nbsp;check_array&nbsp;on&nbsp;X.<br>
&nbsp;<br>
Returns<br>
-------<br>
p&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_classes],&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;n_outputs<br>
&nbsp;&nbsp;&nbsp;&nbsp;such&nbsp;arrays&nbsp;if&nbsp;n_outputs&nbsp;&gt;&nbsp;1.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;class&nbsp;probabilities&nbsp;of&nbsp;the&nbsp;input&nbsp;samples.&nbsp;The&nbsp;order&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;classes&nbsp;corresponds&nbsp;to&nbsp;that&nbsp;in&nbsp;the&nbsp;attribute&nbsp;`classes_`.</tt></dd></dl>

<hr>
Methods inherited from <a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>:<br>
<dl><dt><a name="ExtraTreeClassifier-apply"><strong>apply</strong></a>(self, X, check_input=True)</dt><dd><tt>Returns&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;leaf&nbsp;that&nbsp;each&nbsp;sample&nbsp;is&nbsp;predicted&nbsp;as.<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.17<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array_like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
X_leaves&nbsp;:&nbsp;array_like,&nbsp;shape&nbsp;=&nbsp;[n_samples,]<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;each&nbsp;datapoint&nbsp;x&nbsp;in&nbsp;X,&nbsp;return&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;leaf&nbsp;x<br>
&nbsp;&nbsp;&nbsp;&nbsp;ends&nbsp;up&nbsp;in.&nbsp;Leaves&nbsp;are&nbsp;numbered&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;``[0;&nbsp;self.<strong>tree_</strong>.node_count)``,&nbsp;possibly&nbsp;with&nbsp;gaps&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;numbering.</tt></dd></dl>

<dl><dt><a name="ExtraTreeClassifier-decision_path"><strong>decision_path</strong></a>(self, X, check_input=True)</dt><dd><tt>Return&nbsp;the&nbsp;decision&nbsp;path&nbsp;in&nbsp;the&nbsp;tree<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.18<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array_like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
indicator&nbsp;:&nbsp;sparse&nbsp;csr&nbsp;array,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_nodes]<br>
&nbsp;&nbsp;&nbsp;&nbsp;Return&nbsp;a&nbsp;node&nbsp;indicator&nbsp;matrix&nbsp;where&nbsp;non&nbsp;zero&nbsp;elements<br>
&nbsp;&nbsp;&nbsp;&nbsp;indicates&nbsp;that&nbsp;the&nbsp;samples&nbsp;goes&nbsp;through&nbsp;the&nbsp;nodes.</tt></dd></dl>

<dl><dt><a name="ExtraTreeClassifier-predict"><strong>predict</strong></a>(self, X, check_input=True)</dt><dd><tt>Predict&nbsp;class&nbsp;or&nbsp;regression&nbsp;value&nbsp;for&nbsp;X.<br>
&nbsp;<br>
For&nbsp;a&nbsp;classification&nbsp;model,&nbsp;the&nbsp;predicted&nbsp;class&nbsp;for&nbsp;each&nbsp;sample&nbsp;in&nbsp;X&nbsp;is<br>
returned.&nbsp;For&nbsp;a&nbsp;regression&nbsp;model,&nbsp;the&nbsp;predicted&nbsp;value&nbsp;based&nbsp;on&nbsp;X&nbsp;is<br>
returned.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
y&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;[n_samples,&nbsp;n_outputs]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;predicted&nbsp;classes,&nbsp;or&nbsp;the&nbsp;predict&nbsp;values.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>:<br>
<dl><dt><strong>feature_importances_</strong></dt>
<dd><tt>Return&nbsp;the&nbsp;feature&nbsp;importances.<br>
&nbsp;<br>
The&nbsp;importance&nbsp;of&nbsp;a&nbsp;feature&nbsp;is&nbsp;computed&nbsp;as&nbsp;the&nbsp;(normalized)&nbsp;total<br>
reduction&nbsp;of&nbsp;the&nbsp;criterion&nbsp;brought&nbsp;by&nbsp;that&nbsp;feature.<br>
It&nbsp;is&nbsp;also&nbsp;known&nbsp;as&nbsp;the&nbsp;Gini&nbsp;importance.<br>
&nbsp;<br>
Returns<br>
-------<br>
feature_importances_&nbsp;:&nbsp;array,&nbsp;shape&nbsp;=&nbsp;[n_features]</tt></dd>
</dl>
<hr>
Methods inherited from <a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a>:<br>
<dl><dt><a name="ExtraTreeClassifier-__getstate__"><strong>__getstate__</strong></a>(self)</dt></dl>

<dl><dt><a name="ExtraTreeClassifier-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="ExtraTreeClassifier-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="ExtraTreeClassifier-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><tt>Get&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
Parameters<br>
----------<br>
deep&nbsp;:&nbsp;boolean,&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;True,&nbsp;will&nbsp;return&nbsp;the&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;contained&nbsp;subobjects&nbsp;that&nbsp;are&nbsp;estimators.<br>
&nbsp;<br>
Returns<br>
-------<br>
params&nbsp;:&nbsp;mapping&nbsp;of&nbsp;string&nbsp;to&nbsp;any<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;names&nbsp;mapped&nbsp;to&nbsp;their&nbsp;values.</tt></dd></dl>

<dl><dt><a name="ExtraTreeClassifier-set_params"><strong>set_params</strong></a>(self, **params)</dt><dd><tt>Set&nbsp;the&nbsp;parameters&nbsp;of&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
The&nbsp;method&nbsp;works&nbsp;on&nbsp;simple&nbsp;estimators&nbsp;as&nbsp;well&nbsp;as&nbsp;on&nbsp;nested&nbsp;objects<br>
(such&nbsp;as&nbsp;pipelines).&nbsp;The&nbsp;latter&nbsp;have&nbsp;parameters&nbsp;of&nbsp;the&nbsp;form<br>
``&lt;component&gt;__&lt;parameter&gt;``&nbsp;so&nbsp;that&nbsp;it's&nbsp;possible&nbsp;to&nbsp;update&nbsp;each<br>
component&nbsp;of&nbsp;a&nbsp;nested&nbsp;object.<br>
&nbsp;<br>
Returns<br>
-------<br>
self</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Methods inherited from <a href="sklearn.base.html#ClassifierMixin">sklearn.base.ClassifierMixin</a>:<br>
<dl><dt><a name="ExtraTreeClassifier-score"><strong>score</strong></a>(self, X, y, sample_weight=None)</dt><dd><tt>Returns&nbsp;the&nbsp;mean&nbsp;accuracy&nbsp;on&nbsp;the&nbsp;given&nbsp;test&nbsp;data&nbsp;and&nbsp;labels.<br>
&nbsp;<br>
In&nbsp;multi-label&nbsp;classification,&nbsp;this&nbsp;is&nbsp;the&nbsp;subset&nbsp;accuracy<br>
which&nbsp;is&nbsp;a&nbsp;harsh&nbsp;metric&nbsp;since&nbsp;you&nbsp;require&nbsp;for&nbsp;each&nbsp;sample&nbsp;that<br>
each&nbsp;label&nbsp;set&nbsp;be&nbsp;correctly&nbsp;predicted.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;(n_samples,&nbsp;n_features)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Test&nbsp;samples.<br>
&nbsp;<br>
y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;(n_samples)&nbsp;or&nbsp;(n_samples,&nbsp;n_outputs)<br>
&nbsp;&nbsp;&nbsp;&nbsp;True&nbsp;labels&nbsp;for&nbsp;X.<br>
&nbsp;<br>
sample_weight&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples],&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sample&nbsp;weights.<br>
&nbsp;<br>
Returns<br>
-------<br>
score&nbsp;:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;Mean&nbsp;accuracy&nbsp;of&nbsp;self.<a href="#ExtraTreeClassifier-predict">predict</a>(X)&nbsp;wrt.&nbsp;y.</tt></dd></dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="ExtraTreeRegressor">class <strong>ExtraTreeRegressor</strong></a>(<a href="sklearn.tree.tree.html#DecisionTreeRegressor">DecisionTreeRegressor</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>An&nbsp;extremely&nbsp;randomized&nbsp;tree&nbsp;regressor.<br>
&nbsp;<br>
Extra-trees&nbsp;differ&nbsp;from&nbsp;classic&nbsp;decision&nbsp;trees&nbsp;in&nbsp;the&nbsp;way&nbsp;they&nbsp;are&nbsp;built.<br>
When&nbsp;looking&nbsp;for&nbsp;the&nbsp;best&nbsp;split&nbsp;to&nbsp;separate&nbsp;the&nbsp;samples&nbsp;of&nbsp;a&nbsp;node&nbsp;into&nbsp;two<br>
groups,&nbsp;random&nbsp;splits&nbsp;are&nbsp;drawn&nbsp;for&nbsp;each&nbsp;of&nbsp;the&nbsp;`max_features`&nbsp;randomly<br>
selected&nbsp;features&nbsp;and&nbsp;the&nbsp;best&nbsp;split&nbsp;among&nbsp;those&nbsp;is&nbsp;chosen.&nbsp;When<br>
`max_features`&nbsp;is&nbsp;set&nbsp;1,&nbsp;this&nbsp;amounts&nbsp;to&nbsp;building&nbsp;a&nbsp;totally&nbsp;random<br>
decision&nbsp;tree.<br>
&nbsp;<br>
Warning:&nbsp;Extra-trees&nbsp;should&nbsp;only&nbsp;be&nbsp;used&nbsp;within&nbsp;ensemble&nbsp;methods.<br>
&nbsp;<br>
Read&nbsp;more&nbsp;in&nbsp;the&nbsp;:ref:`User&nbsp;Guide&nbsp;&lt;tree&gt;`.<br>
&nbsp;<br>
Parameters<br>
----------<br>
criterion&nbsp;:&nbsp;string,&nbsp;optional&nbsp;(default="mse")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;function&nbsp;to&nbsp;measure&nbsp;the&nbsp;quality&nbsp;of&nbsp;a&nbsp;split.&nbsp;Supported&nbsp;criteria<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;"mse"&nbsp;for&nbsp;the&nbsp;mean&nbsp;squared&nbsp;error,&nbsp;which&nbsp;is&nbsp;equal&nbsp;to&nbsp;variance<br>
&nbsp;&nbsp;&nbsp;&nbsp;reduction&nbsp;as&nbsp;feature&nbsp;selection&nbsp;criterion,&nbsp;and&nbsp;"mae"&nbsp;for&nbsp;the&nbsp;mean<br>
&nbsp;&nbsp;&nbsp;&nbsp;absolute&nbsp;error.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionadded::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mean&nbsp;Absolute&nbsp;Error&nbsp;(MAE)&nbsp;criterion.<br>
&nbsp;<br>
splitter&nbsp;:&nbsp;string,&nbsp;optional&nbsp;(default="random")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;strategy&nbsp;used&nbsp;to&nbsp;choose&nbsp;the&nbsp;split&nbsp;at&nbsp;each&nbsp;node.&nbsp;Supported<br>
&nbsp;&nbsp;&nbsp;&nbsp;strategies&nbsp;are&nbsp;"best"&nbsp;to&nbsp;choose&nbsp;the&nbsp;best&nbsp;split&nbsp;and&nbsp;"random"&nbsp;to&nbsp;choose<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;best&nbsp;random&nbsp;split.<br>
&nbsp;<br>
max_depth&nbsp;:&nbsp;int&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;tree.&nbsp;If&nbsp;None,&nbsp;then&nbsp;nodes&nbsp;are&nbsp;expanded&nbsp;until<br>
&nbsp;&nbsp;&nbsp;&nbsp;all&nbsp;leaves&nbsp;are&nbsp;pure&nbsp;or&nbsp;until&nbsp;all&nbsp;leaves&nbsp;contain&nbsp;less&nbsp;than<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_samples_split&nbsp;samples.<br>
&nbsp;<br>
min_samples_split&nbsp;:&nbsp;int,&nbsp;float,&nbsp;optional&nbsp;(default=2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;split&nbsp;an&nbsp;internal&nbsp;node:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`min_samples_split`&nbsp;as&nbsp;the&nbsp;minimum&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`min_samples_split`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ceil(min_samples_split&nbsp;*&nbsp;n_samples)`&nbsp;are&nbsp;the&nbsp;minimum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;split.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Added&nbsp;float&nbsp;values&nbsp;for&nbsp;fractions.<br>
&nbsp;<br>
min_samples_leaf&nbsp;:&nbsp;int,&nbsp;float,&nbsp;optional&nbsp;(default=1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;number&nbsp;of&nbsp;samples&nbsp;required&nbsp;to&nbsp;be&nbsp;at&nbsp;a&nbsp;leaf&nbsp;node.<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;split&nbsp;point&nbsp;at&nbsp;any&nbsp;depth&nbsp;will&nbsp;only&nbsp;be&nbsp;considered&nbsp;if&nbsp;it&nbsp;leaves&nbsp;at<br>
&nbsp;&nbsp;&nbsp;&nbsp;least&nbsp;``min_samples_leaf``&nbsp;training&nbsp;samples&nbsp;in&nbsp;each&nbsp;of&nbsp;the&nbsp;left&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;right&nbsp;branches.&nbsp;&nbsp;This&nbsp;may&nbsp;have&nbsp;the&nbsp;effect&nbsp;of&nbsp;smoothing&nbsp;the&nbsp;model,<br>
&nbsp;&nbsp;&nbsp;&nbsp;especially&nbsp;in&nbsp;regression.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`min_samples_leaf`&nbsp;as&nbsp;the&nbsp;minimum&nbsp;number.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`min_samples_leaf`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ceil(min_samples_leaf&nbsp;*&nbsp;n_samples)`&nbsp;are&nbsp;the&nbsp;minimum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;samples&nbsp;for&nbsp;each&nbsp;node.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.18<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Added&nbsp;float&nbsp;values&nbsp;for&nbsp;fractions.<br>
&nbsp;<br>
min_weight_fraction_leaf&nbsp;:&nbsp;float,&nbsp;optional&nbsp;(default=0.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;minimum&nbsp;weighted&nbsp;fraction&nbsp;of&nbsp;the&nbsp;sum&nbsp;total&nbsp;of&nbsp;weights&nbsp;(of&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;input&nbsp;samples)&nbsp;required&nbsp;to&nbsp;be&nbsp;at&nbsp;a&nbsp;leaf&nbsp;node.&nbsp;Samples&nbsp;have<br>
&nbsp;&nbsp;&nbsp;&nbsp;equal&nbsp;weight&nbsp;when&nbsp;sample_weight&nbsp;is&nbsp;not&nbsp;provided.<br>
&nbsp;<br>
max_features&nbsp;:&nbsp;int,&nbsp;float,&nbsp;string&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default="auto")<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;features&nbsp;to&nbsp;consider&nbsp;when&nbsp;looking&nbsp;for&nbsp;the&nbsp;best&nbsp;split:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;int,&nbsp;then&nbsp;consider&nbsp;`max_features`&nbsp;features&nbsp;at&nbsp;each&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;float,&nbsp;then&nbsp;`max_features`&nbsp;is&nbsp;a&nbsp;fraction&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`int(max_features&nbsp;*&nbsp;n_features)`&nbsp;features&nbsp;are&nbsp;considered&nbsp;at&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;split.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"auto",&nbsp;then&nbsp;`max_features=n_features`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"sqrt",&nbsp;then&nbsp;`max_features=sqrt(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;"log2",&nbsp;then&nbsp;`max_features=log2(n_features)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;If&nbsp;None,&nbsp;then&nbsp;`max_features=n_features`.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Note:&nbsp;the&nbsp;search&nbsp;for&nbsp;a&nbsp;split&nbsp;does&nbsp;not&nbsp;stop&nbsp;until&nbsp;at&nbsp;least&nbsp;one<br>
&nbsp;&nbsp;&nbsp;&nbsp;valid&nbsp;partition&nbsp;of&nbsp;the&nbsp;node&nbsp;samples&nbsp;is&nbsp;found,&nbsp;even&nbsp;if&nbsp;it&nbsp;requires&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;effectively&nbsp;inspect&nbsp;more&nbsp;than&nbsp;``max_features``&nbsp;features.<br>
&nbsp;<br>
random_state&nbsp;:&nbsp;int,&nbsp;RandomState&nbsp;instance&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;int,&nbsp;random_state&nbsp;is&nbsp;the&nbsp;seed&nbsp;used&nbsp;by&nbsp;the&nbsp;random&nbsp;number&nbsp;generator;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;RandomState&nbsp;instance,&nbsp;random_state&nbsp;is&nbsp;the&nbsp;random&nbsp;number&nbsp;generator;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None,&nbsp;the&nbsp;random&nbsp;number&nbsp;generator&nbsp;is&nbsp;the&nbsp;RandomState&nbsp;instance&nbsp;used<br>
&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;`np.random`.<br>
&nbsp;<br>
min_impurity_decrease&nbsp;:&nbsp;float,&nbsp;optional&nbsp;(default=0.)<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;node&nbsp;will&nbsp;be&nbsp;split&nbsp;if&nbsp;this&nbsp;split&nbsp;induces&nbsp;a&nbsp;decrease&nbsp;of&nbsp;the&nbsp;impurity<br>
&nbsp;&nbsp;&nbsp;&nbsp;greater&nbsp;than&nbsp;or&nbsp;equal&nbsp;to&nbsp;this&nbsp;value.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;weighted&nbsp;impurity&nbsp;decrease&nbsp;equation&nbsp;is&nbsp;the&nbsp;following::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;N_t&nbsp;/&nbsp;N&nbsp;*&nbsp;(impurity&nbsp;-&nbsp;N_t_R&nbsp;/&nbsp;N_t&nbsp;*&nbsp;right_impurity<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;N_t_L&nbsp;/&nbsp;N_t&nbsp;*&nbsp;left_impurity)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;where&nbsp;``N``&nbsp;is&nbsp;the&nbsp;total&nbsp;number&nbsp;of&nbsp;samples,&nbsp;``N_t``&nbsp;is&nbsp;the&nbsp;number&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;samples&nbsp;at&nbsp;the&nbsp;current&nbsp;node,&nbsp;``N_t_L``&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;left&nbsp;child,&nbsp;and&nbsp;``N_t_R``&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;samples&nbsp;in&nbsp;the&nbsp;right&nbsp;child.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;``N``,&nbsp;``N_t``,&nbsp;``N_t_R``&nbsp;and&nbsp;``N_t_L``&nbsp;all&nbsp;refer&nbsp;to&nbsp;the&nbsp;weighted&nbsp;sum,<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;``sample_weight``&nbsp;is&nbsp;passed.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionadded::&nbsp;0.19<br>
&nbsp;<br>
min_impurity_split&nbsp;:&nbsp;float,&nbsp;(default=1e-7)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Threshold&nbsp;for&nbsp;early&nbsp;stopping&nbsp;in&nbsp;tree&nbsp;growth.&nbsp;A&nbsp;node&nbsp;will&nbsp;split<br>
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;its&nbsp;impurity&nbsp;is&nbsp;above&nbsp;the&nbsp;threshold,&nbsp;otherwise&nbsp;it&nbsp;is&nbsp;a&nbsp;leaf.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;deprecated::&nbsp;0.19<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_split``&nbsp;has&nbsp;been&nbsp;deprecated&nbsp;in&nbsp;favor&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_decrease``&nbsp;in&nbsp;0.19.&nbsp;The&nbsp;default&nbsp;value&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``min_impurity_split``&nbsp;will&nbsp;change&nbsp;from&nbsp;1e-7&nbsp;to&nbsp;0&nbsp;in&nbsp;0.23&nbsp;and&nbsp;it<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;be&nbsp;removed&nbsp;in&nbsp;0.25.&nbsp;Use&nbsp;``min_impurity_decrease``&nbsp;instead.<br>
&nbsp;<br>
max_leaf_nodes&nbsp;:&nbsp;int&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Grow&nbsp;a&nbsp;tree&nbsp;with&nbsp;``max_leaf_nodes``&nbsp;in&nbsp;best-first&nbsp;fashion.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Best&nbsp;nodes&nbsp;are&nbsp;defined&nbsp;as&nbsp;relative&nbsp;reduction&nbsp;in&nbsp;impurity.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;None&nbsp;then&nbsp;unlimited&nbsp;number&nbsp;of&nbsp;leaf&nbsp;nodes.<br>
&nbsp;<br>
&nbsp;<br>
See&nbsp;also<br>
--------<br>
<a href="#ExtraTreeClassifier">ExtraTreeClassifier</a>,&nbsp;sklearn.ensemble.ExtraTreesClassifier,<br>
sklearn.ensemble.ExtraTreesRegressor<br>
&nbsp;<br>
Notes<br>
-----<br>
The&nbsp;default&nbsp;values&nbsp;for&nbsp;the&nbsp;parameters&nbsp;controlling&nbsp;the&nbsp;size&nbsp;of&nbsp;the&nbsp;trees<br>
(e.g.&nbsp;``max_depth``,&nbsp;``min_samples_leaf``,&nbsp;etc.)&nbsp;lead&nbsp;to&nbsp;fully&nbsp;grown&nbsp;and<br>
unpruned&nbsp;trees&nbsp;which&nbsp;can&nbsp;potentially&nbsp;be&nbsp;very&nbsp;large&nbsp;on&nbsp;some&nbsp;data&nbsp;sets.&nbsp;To<br>
reduce&nbsp;memory&nbsp;consumption,&nbsp;the&nbsp;complexity&nbsp;and&nbsp;size&nbsp;of&nbsp;the&nbsp;trees&nbsp;should&nbsp;be<br>
controlled&nbsp;by&nbsp;setting&nbsp;those&nbsp;parameter&nbsp;values.<br>
&nbsp;<br>
References<br>
----------<br>
&nbsp;<br>
..&nbsp;[1]&nbsp;P.&nbsp;Geurts,&nbsp;D.&nbsp;Ernst.,&nbsp;and&nbsp;L.&nbsp;Wehenkel,&nbsp;"Extremely&nbsp;randomized&nbsp;trees",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Machine&nbsp;Learning,&nbsp;63(1),&nbsp;3-42,&nbsp;2006.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="sklearn.tree.tree.html#ExtraTreeRegressor">ExtraTreeRegressor</a></dd>
<dd><a href="sklearn.tree.tree.html#DecisionTreeRegressor">DecisionTreeRegressor</a></dd>
<dd><a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a></dd>
<dd>abc.NewBase</dd>
<dd><a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a></dd>
<dd><a href="sklearn.base.html#RegressorMixin">sklearn.base.RegressorMixin</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="ExtraTreeRegressor-__init__"><strong>__init__</strong></a>(self, criterion='mse', splitter='random', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', random_state=None, min_impurity_decrease=0.0, min_impurity_split=None, max_leaf_nodes=None)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>__abstractmethods__</strong> = frozenset()</dl>

<hr>
Methods inherited from <a href="sklearn.tree.tree.html#DecisionTreeRegressor">DecisionTreeRegressor</a>:<br>
<dl><dt><a name="ExtraTreeRegressor-fit"><strong>fit</strong></a>(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)</dt><dd><tt>Build&nbsp;a&nbsp;decision&nbsp;tree&nbsp;regressor&nbsp;from&nbsp;the&nbsp;training&nbsp;set&nbsp;(X,&nbsp;y).<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;training&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csc_matrix``.<br>
&nbsp;<br>
y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;[n_samples,&nbsp;n_outputs]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;target&nbsp;values&nbsp;(real&nbsp;numbers).&nbsp;Use&nbsp;``dtype=np.float64``&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;``order='C'``&nbsp;for&nbsp;maximum&nbsp;efficiency.<br>
&nbsp;<br>
sample_weight&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;None<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sample&nbsp;weights.&nbsp;If&nbsp;None,&nbsp;then&nbsp;samples&nbsp;are&nbsp;equally&nbsp;weighted.&nbsp;Splits<br>
&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;would&nbsp;create&nbsp;child&nbsp;nodes&nbsp;with&nbsp;net&nbsp;zero&nbsp;or&nbsp;negative&nbsp;weight&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;ignored&nbsp;while&nbsp;searching&nbsp;for&nbsp;a&nbsp;split&nbsp;in&nbsp;each&nbsp;node.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
X_idx_sorted&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features],&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;indexes&nbsp;of&nbsp;the&nbsp;sorted&nbsp;training&nbsp;input&nbsp;samples.&nbsp;If&nbsp;many&nbsp;tree<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;grown&nbsp;on&nbsp;the&nbsp;same&nbsp;dataset,&nbsp;this&nbsp;allows&nbsp;the&nbsp;ordering&nbsp;to&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;between&nbsp;trees.&nbsp;If&nbsp;None,&nbsp;the&nbsp;data&nbsp;will&nbsp;be&nbsp;sorted&nbsp;here.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;to&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
self&nbsp;:&nbsp;object</tt></dd></dl>

<hr>
Methods inherited from <a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>:<br>
<dl><dt><a name="ExtraTreeRegressor-apply"><strong>apply</strong></a>(self, X, check_input=True)</dt><dd><tt>Returns&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;leaf&nbsp;that&nbsp;each&nbsp;sample&nbsp;is&nbsp;predicted&nbsp;as.<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.17<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array_like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
X_leaves&nbsp;:&nbsp;array_like,&nbsp;shape&nbsp;=&nbsp;[n_samples,]<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;each&nbsp;datapoint&nbsp;x&nbsp;in&nbsp;X,&nbsp;return&nbsp;the&nbsp;index&nbsp;of&nbsp;the&nbsp;leaf&nbsp;x<br>
&nbsp;&nbsp;&nbsp;&nbsp;ends&nbsp;up&nbsp;in.&nbsp;Leaves&nbsp;are&nbsp;numbered&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;``[0;&nbsp;self.<strong>tree_</strong>.node_count)``,&nbsp;possibly&nbsp;with&nbsp;gaps&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;numbering.</tt></dd></dl>

<dl><dt><a name="ExtraTreeRegressor-decision_path"><strong>decision_path</strong></a>(self, X, check_input=True)</dt><dd><tt>Return&nbsp;the&nbsp;decision&nbsp;path&nbsp;in&nbsp;the&nbsp;tree<br>
&nbsp;<br>
..&nbsp;versionadded::&nbsp;0.18<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array_like&nbsp;or&nbsp;sparse&nbsp;matrix,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
indicator&nbsp;:&nbsp;sparse&nbsp;csr&nbsp;array,&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_nodes]<br>
&nbsp;&nbsp;&nbsp;&nbsp;Return&nbsp;a&nbsp;node&nbsp;indicator&nbsp;matrix&nbsp;where&nbsp;non&nbsp;zero&nbsp;elements<br>
&nbsp;&nbsp;&nbsp;&nbsp;indicates&nbsp;that&nbsp;the&nbsp;samples&nbsp;goes&nbsp;through&nbsp;the&nbsp;nodes.</tt></dd></dl>

<dl><dt><a name="ExtraTreeRegressor-predict"><strong>predict</strong></a>(self, X, check_input=True)</dt><dd><tt>Predict&nbsp;class&nbsp;or&nbsp;regression&nbsp;value&nbsp;for&nbsp;X.<br>
&nbsp;<br>
For&nbsp;a&nbsp;classification&nbsp;model,&nbsp;the&nbsp;predicted&nbsp;class&nbsp;for&nbsp;each&nbsp;sample&nbsp;in&nbsp;X&nbsp;is<br>
returned.&nbsp;For&nbsp;a&nbsp;regression&nbsp;model,&nbsp;the&nbsp;predicted&nbsp;value&nbsp;based&nbsp;on&nbsp;X&nbsp;is<br>
returned.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like&nbsp;or&nbsp;sparse&nbsp;matrix&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples,&nbsp;n_features]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;input&nbsp;samples.&nbsp;Internally,&nbsp;it&nbsp;will&nbsp;be&nbsp;converted&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;``dtype=np.float32``&nbsp;and&nbsp;if&nbsp;a&nbsp;sparse&nbsp;matrix&nbsp;is&nbsp;provided<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;a&nbsp;sparse&nbsp;``csr_matrix``.<br>
&nbsp;<br>
check_input&nbsp;:&nbsp;boolean,&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allow&nbsp;to&nbsp;bypass&nbsp;several&nbsp;input&nbsp;checking.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Don't&nbsp;use&nbsp;this&nbsp;parameter&nbsp;unless&nbsp;you&nbsp;know&nbsp;what&nbsp;you&nbsp;do.<br>
&nbsp;<br>
Returns<br>
-------<br>
y&nbsp;:&nbsp;array&nbsp;of&nbsp;shape&nbsp;=&nbsp;[n_samples]&nbsp;or&nbsp;[n_samples,&nbsp;n_outputs]<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;predicted&nbsp;classes,&nbsp;or&nbsp;the&nbsp;predict&nbsp;values.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="sklearn.tree.tree.html#BaseDecisionTree">BaseDecisionTree</a>:<br>
<dl><dt><strong>feature_importances_</strong></dt>
<dd><tt>Return&nbsp;the&nbsp;feature&nbsp;importances.<br>
&nbsp;<br>
The&nbsp;importance&nbsp;of&nbsp;a&nbsp;feature&nbsp;is&nbsp;computed&nbsp;as&nbsp;the&nbsp;(normalized)&nbsp;total<br>
reduction&nbsp;of&nbsp;the&nbsp;criterion&nbsp;brought&nbsp;by&nbsp;that&nbsp;feature.<br>
It&nbsp;is&nbsp;also&nbsp;known&nbsp;as&nbsp;the&nbsp;Gini&nbsp;importance.<br>
&nbsp;<br>
Returns<br>
-------<br>
feature_importances_&nbsp;:&nbsp;array,&nbsp;shape&nbsp;=&nbsp;[n_features]</tt></dd>
</dl>
<hr>
Methods inherited from <a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a>:<br>
<dl><dt><a name="ExtraTreeRegressor-__getstate__"><strong>__getstate__</strong></a>(self)</dt></dl>

<dl><dt><a name="ExtraTreeRegressor-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="ExtraTreeRegressor-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="ExtraTreeRegressor-get_params"><strong>get_params</strong></a>(self, deep=True)</dt><dd><tt>Get&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
Parameters<br>
----------<br>
deep&nbsp;:&nbsp;boolean,&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;True,&nbsp;will&nbsp;return&nbsp;the&nbsp;parameters&nbsp;for&nbsp;this&nbsp;estimator&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;contained&nbsp;subobjects&nbsp;that&nbsp;are&nbsp;estimators.<br>
&nbsp;<br>
Returns<br>
-------<br>
params&nbsp;:&nbsp;mapping&nbsp;of&nbsp;string&nbsp;to&nbsp;any<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;names&nbsp;mapped&nbsp;to&nbsp;their&nbsp;values.</tt></dd></dl>

<dl><dt><a name="ExtraTreeRegressor-set_params"><strong>set_params</strong></a>(self, **params)</dt><dd><tt>Set&nbsp;the&nbsp;parameters&nbsp;of&nbsp;this&nbsp;estimator.<br>
&nbsp;<br>
The&nbsp;method&nbsp;works&nbsp;on&nbsp;simple&nbsp;estimators&nbsp;as&nbsp;well&nbsp;as&nbsp;on&nbsp;nested&nbsp;objects<br>
(such&nbsp;as&nbsp;pipelines).&nbsp;The&nbsp;latter&nbsp;have&nbsp;parameters&nbsp;of&nbsp;the&nbsp;form<br>
``&lt;component&gt;__&lt;parameter&gt;``&nbsp;so&nbsp;that&nbsp;it's&nbsp;possible&nbsp;to&nbsp;update&nbsp;each<br>
component&nbsp;of&nbsp;a&nbsp;nested&nbsp;object.<br>
&nbsp;<br>
Returns<br>
-------<br>
self</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="sklearn.base.html#BaseEstimator">sklearn.base.BaseEstimator</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Methods inherited from <a href="sklearn.base.html#RegressorMixin">sklearn.base.RegressorMixin</a>:<br>
<dl><dt><a name="ExtraTreeRegressor-score"><strong>score</strong></a>(self, X, y, sample_weight=None)</dt><dd><tt>Returns&nbsp;the&nbsp;coefficient&nbsp;of&nbsp;determination&nbsp;R^2&nbsp;of&nbsp;the&nbsp;prediction.<br>
&nbsp;<br>
The&nbsp;coefficient&nbsp;R^2&nbsp;is&nbsp;defined&nbsp;as&nbsp;(1&nbsp;-&nbsp;u/v),&nbsp;where&nbsp;u&nbsp;is&nbsp;the&nbsp;residual<br>
sum&nbsp;of&nbsp;squares&nbsp;((y_true&nbsp;-&nbsp;y_pred)&nbsp;**&nbsp;2).sum()&nbsp;and&nbsp;v&nbsp;is&nbsp;the&nbsp;total<br>
sum&nbsp;of&nbsp;squares&nbsp;((y_true&nbsp;-&nbsp;y_true.mean())&nbsp;**&nbsp;2).sum().<br>
The&nbsp;best&nbsp;possible&nbsp;score&nbsp;is&nbsp;1.0&nbsp;and&nbsp;it&nbsp;can&nbsp;be&nbsp;negative&nbsp;(because&nbsp;the<br>
model&nbsp;can&nbsp;be&nbsp;arbitrarily&nbsp;worse).&nbsp;A&nbsp;constant&nbsp;model&nbsp;that&nbsp;always<br>
predicts&nbsp;the&nbsp;expected&nbsp;value&nbsp;of&nbsp;y,&nbsp;disregarding&nbsp;the&nbsp;input&nbsp;features,<br>
would&nbsp;get&nbsp;a&nbsp;R^2&nbsp;score&nbsp;of&nbsp;0.0.<br>
&nbsp;<br>
Parameters<br>
----------<br>
X&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;(n_samples,&nbsp;n_features)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Test&nbsp;samples.&nbsp;For&nbsp;some&nbsp;estimators&nbsp;this&nbsp;may&nbsp;be&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;precomputed&nbsp;kernel&nbsp;matrix&nbsp;instead,&nbsp;shape&nbsp;=&nbsp;(n_samples,<br>
&nbsp;&nbsp;&nbsp;&nbsp;n_samples_fitted],&nbsp;where&nbsp;n_samples_fitted&nbsp;is&nbsp;the&nbsp;number&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;samples&nbsp;used&nbsp;in&nbsp;the&nbsp;fitting&nbsp;for&nbsp;the&nbsp;estimator.<br>
&nbsp;<br>
y&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;(n_samples)&nbsp;or&nbsp;(n_samples,&nbsp;n_outputs)<br>
&nbsp;&nbsp;&nbsp;&nbsp;True&nbsp;values&nbsp;for&nbsp;X.<br>
&nbsp;<br>
sample_weight&nbsp;:&nbsp;array-like,&nbsp;shape&nbsp;=&nbsp;[n_samples],&nbsp;optional<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sample&nbsp;weights.<br>
&nbsp;<br>
Returns<br>
-------<br>
score&nbsp;:&nbsp;float<br>
&nbsp;&nbsp;&nbsp;&nbsp;R^2&nbsp;of&nbsp;self.<a href="#ExtraTreeRegressor-predict">predict</a>(X)&nbsp;wrt.&nbsp;y.</tt></dd></dl>

</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#eeaa77">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Functions</strong></big></font></td></tr>
    
<tr><td bgcolor="#eeaa77"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl><dt><a name="-export_graphviz"><strong>export_graphviz</strong></a>(decision_tree, out_file=None, max_depth=None, feature_names=None, class_names=None, label='all', filled=False, leaves_parallel=False, impurity=True, node_ids=False, proportion=False, rotate=False, rounded=False, special_characters=False, precision=3)</dt><dd><tt>Export&nbsp;a&nbsp;decision&nbsp;tree&nbsp;in&nbsp;DOT&nbsp;format.<br>
&nbsp;<br>
This&nbsp;function&nbsp;generates&nbsp;a&nbsp;GraphViz&nbsp;representation&nbsp;of&nbsp;the&nbsp;decision&nbsp;tree,<br>
which&nbsp;is&nbsp;then&nbsp;written&nbsp;into&nbsp;`out_file`.&nbsp;Once&nbsp;exported,&nbsp;graphical&nbsp;renderings<br>
can&nbsp;be&nbsp;generated&nbsp;using,&nbsp;for&nbsp;example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;$&nbsp;dot&nbsp;-Tps&nbsp;tree.dot&nbsp;-o&nbsp;tree.ps&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(PostScript&nbsp;format)<br>
&nbsp;&nbsp;&nbsp;&nbsp;$&nbsp;dot&nbsp;-Tpng&nbsp;tree.dot&nbsp;-o&nbsp;tree.png&nbsp;&nbsp;&nbsp;&nbsp;(PNG&nbsp;format)<br>
&nbsp;<br>
The&nbsp;sample&nbsp;counts&nbsp;that&nbsp;are&nbsp;shown&nbsp;are&nbsp;weighted&nbsp;with&nbsp;any&nbsp;sample_weights&nbsp;that<br>
might&nbsp;be&nbsp;present.<br>
&nbsp;<br>
Read&nbsp;more&nbsp;in&nbsp;the&nbsp;:ref:`User&nbsp;Guide&nbsp;&lt;tree&gt;`.<br>
&nbsp;<br>
Parameters<br>
----------<br>
decision_tree&nbsp;:&nbsp;decision&nbsp;tree&nbsp;regressor&nbsp;or&nbsp;classifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;decision&nbsp;tree&nbsp;to&nbsp;be&nbsp;exported&nbsp;to&nbsp;GraphViz.<br>
&nbsp;<br>
out_file&nbsp;:&nbsp;file&nbsp;object&nbsp;or&nbsp;string,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Handle&nbsp;or&nbsp;name&nbsp;of&nbsp;the&nbsp;output&nbsp;file.&nbsp;If&nbsp;``None``,&nbsp;the&nbsp;result&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;returned&nbsp;as&nbsp;a&nbsp;string.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionchanged::&nbsp;0.20<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default&nbsp;of&nbsp;out_file&nbsp;changed&nbsp;from&nbsp;"tree.dot"&nbsp;to&nbsp;None.<br>
&nbsp;<br>
max_depth&nbsp;:&nbsp;int,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;maximum&nbsp;depth&nbsp;of&nbsp;the&nbsp;representation.&nbsp;If&nbsp;None,&nbsp;the&nbsp;tree&nbsp;is&nbsp;fully<br>
&nbsp;&nbsp;&nbsp;&nbsp;generated.<br>
&nbsp;<br>
feature_names&nbsp;:&nbsp;list&nbsp;of&nbsp;strings,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Names&nbsp;of&nbsp;each&nbsp;of&nbsp;the&nbsp;features.<br>
&nbsp;<br>
class_names&nbsp;:&nbsp;list&nbsp;of&nbsp;strings,&nbsp;bool&nbsp;or&nbsp;None,&nbsp;optional&nbsp;(default=None)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Names&nbsp;of&nbsp;each&nbsp;of&nbsp;the&nbsp;target&nbsp;classes&nbsp;in&nbsp;ascending&nbsp;numerical&nbsp;order.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Only&nbsp;relevant&nbsp;for&nbsp;classification&nbsp;and&nbsp;not&nbsp;supported&nbsp;for&nbsp;multi-output.<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;``True``,&nbsp;shows&nbsp;a&nbsp;symbolic&nbsp;representation&nbsp;of&nbsp;the&nbsp;class&nbsp;name.<br>
&nbsp;<br>
label&nbsp;:&nbsp;{'all',&nbsp;'root',&nbsp;'none'},&nbsp;optional&nbsp;(default='all')<br>
&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;show&nbsp;informative&nbsp;labels&nbsp;for&nbsp;impurity,&nbsp;etc.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Options&nbsp;include&nbsp;'all'&nbsp;to&nbsp;show&nbsp;at&nbsp;every&nbsp;node,&nbsp;'root'&nbsp;to&nbsp;show&nbsp;only&nbsp;at<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;top&nbsp;root&nbsp;node,&nbsp;or&nbsp;'none'&nbsp;to&nbsp;not&nbsp;show&nbsp;at&nbsp;any&nbsp;node.<br>
&nbsp;<br>
filled&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;set&nbsp;to&nbsp;``True``,&nbsp;paint&nbsp;nodes&nbsp;to&nbsp;indicate&nbsp;majority&nbsp;class&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;classification,&nbsp;extremity&nbsp;of&nbsp;values&nbsp;for&nbsp;regression,&nbsp;or&nbsp;purity&nbsp;of&nbsp;node<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;multi-output.<br>
&nbsp;<br>
leaves_parallel&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;set&nbsp;to&nbsp;``True``,&nbsp;draw&nbsp;all&nbsp;leaf&nbsp;nodes&nbsp;at&nbsp;the&nbsp;bottom&nbsp;of&nbsp;the&nbsp;tree.<br>
&nbsp;<br>
impurity&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;set&nbsp;to&nbsp;``True``,&nbsp;show&nbsp;the&nbsp;impurity&nbsp;at&nbsp;each&nbsp;node.<br>
&nbsp;<br>
node_ids&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;set&nbsp;to&nbsp;``True``,&nbsp;show&nbsp;the&nbsp;ID&nbsp;number&nbsp;on&nbsp;each&nbsp;node.<br>
&nbsp;<br>
proportion&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;set&nbsp;to&nbsp;``True``,&nbsp;change&nbsp;the&nbsp;display&nbsp;of&nbsp;'values'&nbsp;and/or&nbsp;'samples'<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;be&nbsp;proportions&nbsp;and&nbsp;percentages&nbsp;respectively.<br>
&nbsp;<br>
rotate&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;set&nbsp;to&nbsp;``True``,&nbsp;orient&nbsp;tree&nbsp;left&nbsp;to&nbsp;right&nbsp;rather&nbsp;than&nbsp;top-down.<br>
&nbsp;<br>
rounded&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;set&nbsp;to&nbsp;``True``,&nbsp;draw&nbsp;node&nbsp;boxes&nbsp;with&nbsp;rounded&nbsp;corners&nbsp;and&nbsp;use<br>
&nbsp;&nbsp;&nbsp;&nbsp;Helvetica&nbsp;fonts&nbsp;instead&nbsp;of&nbsp;Times-Roman.<br>
&nbsp;<br>
special_characters&nbsp;:&nbsp;bool,&nbsp;optional&nbsp;(default=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;set&nbsp;to&nbsp;``False``,&nbsp;ignore&nbsp;special&nbsp;characters&nbsp;for&nbsp;PostScript<br>
&nbsp;&nbsp;&nbsp;&nbsp;compatibility.<br>
&nbsp;<br>
precision&nbsp;:&nbsp;int,&nbsp;optional&nbsp;(default=3)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Number&nbsp;of&nbsp;digits&nbsp;of&nbsp;precision&nbsp;for&nbsp;floating&nbsp;point&nbsp;in&nbsp;the&nbsp;values&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;impurity,&nbsp;threshold&nbsp;and&nbsp;value&nbsp;attributes&nbsp;of&nbsp;each&nbsp;node.<br>
&nbsp;<br>
Returns<br>
-------<br>
dot_data&nbsp;:&nbsp;string<br>
&nbsp;&nbsp;&nbsp;&nbsp;String&nbsp;representation&nbsp;of&nbsp;the&nbsp;input&nbsp;tree&nbsp;in&nbsp;GraphViz&nbsp;dot&nbsp;format.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Only&nbsp;returned&nbsp;if&nbsp;``out_file``&nbsp;is&nbsp;None.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;versionadded::&nbsp;0.18<br>
&nbsp;<br>
Examples<br>
--------<br>
&gt;&gt;&gt;&nbsp;from&nbsp;sklearn.datasets&nbsp;import&nbsp;load_iris<br>
&gt;&gt;&gt;&nbsp;from&nbsp;sklearn&nbsp;import&nbsp;tree<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;clf&nbsp;=&nbsp;tree.<a href="#DecisionTreeClassifier">DecisionTreeClassifier</a>()<br>
&gt;&gt;&gt;&nbsp;iris&nbsp;=&nbsp;load_iris()<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;clf&nbsp;=&nbsp;clf.fit(iris.data,&nbsp;iris.target)<br>
&gt;&gt;&gt;&nbsp;tree.<a href="#-export_graphviz">export_graphviz</a>(clf,<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;out_file='tree.dot')&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;doctest:&nbsp;+SKIP</tt></dd></dl>
</td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#55aa55">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Data</strong></big></font></td></tr>
    
<tr><td bgcolor="#55aa55"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><strong>__all__</strong> = ['DecisionTreeClassifier', 'DecisionTreeRegressor', 'ExtraTreeClassifier', 'ExtraTreeRegressor', 'export_graphviz']</td></tr></table>
</body></html>